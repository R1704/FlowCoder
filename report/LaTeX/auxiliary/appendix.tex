
\section{Domain Specific Language (DSL)} \label{app:dsl}

\subsection{Semantics}
\begin{lstlisting}[style=mypy, breaklines=true]
    semantics = {
    "empty": [],
    "cons": _cons,
    "car": _car,
    "cdr": _cdr,
    "empty?": _isEmpty,
    "gt?": _gt,
    "le?": lambda x: lambda y: x <= y,
    "not": lambda x: not x,
    "max": lambda x: lambda y: max(x, y),
    "min": lambda x: lambda y: min(x, y),
    "if": _if,
    "eq?": _eq,
    "*": _multiplication,
    "+": _addition,
    "-": _subtraction,
    "length": len,
    "0": 0,
    "1": 1,
    "2": 2,
    "3": 3,
    "4": 4,
    "5": 5,
    "range": _range,
    "map": _map,
    "iter": _miter,
    "append": lambda x: lambda l: l + [x],
    "unfold": _unfold,
    "index": _index,
    "fold": _fold,
    "is-mod": lambda x: lambda y: y % x == 0 if x != 0 else False,
    "mod": _mod,
    "is-prime": _isPrime,
    "is-square": _isSquare,
    "filter": lambda f: lambda l: [x for x in l if f(x)]
}
\end{lstlisting}

\clearpage
\subsection{Primitive Types}
\begin{lstlisting}[style=mypy, breaklines=true]
    primitive_types = {
    "empty": List(t0),
    "cons": Arrow(t0, Arrow(List(t0), List(t0))),
    "car": Arrow(List(t0), t0),
    "cdr": Arrow(List(t0), List(t0)),
    "empty?": Arrow(List(t0), BOOL),
    "max": Arrow(INT, Arrow(INT, INT)),
    "min": Arrow(INT, Arrow(INT, INT)),
    "gt?": Arrow(INT, Arrow(INT, BOOL)),
    "le?": Arrow(INT, Arrow(INT, BOOL)),
    "not": Arrow(BOOL, BOOL),
    "if": Arrow(BOOL, Arrow(t0, Arrow(t0, t0))),
    "eq?": Arrow(INT, Arrow(INT, BOOL)),
    "*": Arrow(INT, Arrow(INT, INT)),
    "+": Arrow(INT, Arrow(INT, INT)),
    "-": Arrow(INT, Arrow(INT, INT)),
    "length": Arrow(List(t0), INT),
    "0": INT,
    "1": INT,
    "2": INT,
    "3": INT,
    "4": INT,
    "5": INT,
    "range": Arrow(INT, List(INT)),
    "map": Arrow(Arrow(t0, t1), Arrow(List(t0), List(t1))),
    "iter": Arrow(INT, Arrow(Arrow(t0, t0), Arrow(t0, t0))),
    "append": Arrow(t0, Arrow(List(t0), List(t0))),
    "unfold": Arrow(t0, Arrow(Arrow(t0, BOOL), Arrow(Arrow(t0, t1), Arrow(Arrow(t0, t0), List(t1))))),
    "index": Arrow(INT, Arrow(List(t0), t0)),
    "fold": Arrow(List(t0), Arrow(t1, Arrow(Arrow(t0, Arrow(t1, t1)), t1))),
    "is-mod": Arrow(INT, Arrow(INT, BOOL)),
    "mod": Arrow(INT, Arrow(INT, INT)),
    "is-prime": Arrow(INT, BOOL),
    "is-square": Arrow(INT, BOOL),
    "filter": Arrow(Arrow(t0, BOOL), Arrow(List(t0), List(t0))),
}
\end{lstlisting}

\clearpage
\section{Parameters}
\begin{table}[h!]
    \centering
    \begin{tabularx}{\textwidth}{|l|l|X|}
    \hline
    \textbf{Class} & \textbf{Parameter} & \textbf{Value} \\
    \hline
    IOEncoder &  &  \\
     & size\_max & 10 \\
     & d\_model & 512 \\
    \hline
    RuleEncoder & & \\
     & d\_model & 512 \\
    \hline
    GFlowNet &  & \\
     & d\_model & 512 \\
     & num\_heads & 8 \\
     & num\_layers & 2 \\
     & dropout & 0.1 \\
    \hline
    Training & & \\
     & min\_program\_depth & 3 \\
     & max\_program\_depth & 6 \\
     & epochs & 145 \\
     & batch\_size & 4 \\
     & learning\_rate\_trn & $1 \times 10^{-4}$ \\
     & learning\_rate\_gfn & $1 \times 10^{-4}$ \\
     & e\_steps & 500 \\
     & m\_step\_threshold\_init & 150 \\
     & m\_steps & 150 \\
     & alpha & 0.3 \\
     & beta & 0.7 \\
     & epsilon & 0.3 \\
     & replay\_prob & 0.3 \\
     & fantasy\_prob & 0.005 \\

    \hline
    \end{tabularx}
    \caption{Parameters}
    \label{table:params}
    \end{table}


    \subsection{Big experiment}

    \begin{table}[ht]
        \centering
        \caption{Experiment Parameters}
        \begin{tabular}{|l|l|}
        \hline
        \textbf{Variable} & \textbf{Value} \\
        \hline
        \texttt{d\_model} & 512 \\
        \hline
        \texttt{max\_program\_depth} & 4 \\
        \hline
        \texttt{shuffle\_tasks} & True \\
        \hline
        \texttt{n\_tasks} & 145 \\
        \hline
        \texttt{variable\_batch} & False \\
        \hline
        \texttt{train\_ratio} & 0.5 \\
        \hline
        \texttt{seed} & 3 \\
        \hline
        \texttt{n\_examples\_max} & (based on \texttt{data.nb\_examples\_max}) \\
        \hline
        \texttt{size\_max} & 10 \\
        \hline
        \texttt{lexicon} & (based on \texttt{data.lexicon}) \\
        \hline
        \texttt{cfg} & (based on \texttt{data.cfg}) \\
        \hline
        \texttt{num\_heads} & 8 \\
        \hline
        \texttt{num\_layers} & 2 \\
        \hline
        \texttt{dropout} & 0.1 \\
        \hline
        \texttt{min\_program\_depth} & (based on \texttt{data.max\_program\_depth}) \\
        \hline
        \texttt{max\_program\_depth} & (based on \texttt{data.max\_program\_depth}) \\
        \hline
        \texttt{epochs} & 5 \\
        \hline
        \texttt{batch\_size} & 4 \\
        \hline
        \texttt{learning\_rate\_gen} & $1 \times 10^{-4}$ \\
        \hline
        \texttt{learning\_rate\_pol} & $1 \times 10^{-4}$ \\
        \hline
        \texttt{e\_steps} & 2000 \\
        \hline
        \texttt{m\_step\_threshold\_init} & 150 \\
        \hline
        \texttt{m\_steps} & 2000 \\
        \hline
        \texttt{inference\_steps} & 100 \\
        \hline
        \texttt{alpha} & 0.3 \\
        \hline
        \texttt{beta} & 0.7 \\
        \hline
        \texttt{epsilon} & 0.3 \\
        \hline
        \texttt{replay\_prob} & 1 \\
        \hline
        \texttt{fantasy\_prob} & 1 \\
        \hline
        \texttt{data} & (based on \texttt{data}) \\
        \hline
        \texttt{model} & (based on \texttt{model}) \\
        \hline
        \texttt{save\_checkpoint} & (based on \texttt{save\_checkpoint}) \\
        \hline
        \end{tabular}
        \end{table}
    