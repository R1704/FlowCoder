
\section{Domain Specific Language (DSL)} \label{app:dsl}

\subsection{Semantics}
\begin{lstlisting}[style=mypy, breaklines=true]
    semantics = {
    "empty": [],
    "cons": _cons,
    "car": _car,
    "cdr": _cdr,
    "empty?": _isEmpty,
    "gt?": _gt,
    "le?": lambda x: lambda y: x <= y,
    "not": lambda x: not x,
    "max": lambda x: lambda y: max(x, y),
    "min": lambda x: lambda y: min(x, y),
    "if": _if,
    "eq?": _eq,
    "*": _multiplication,
    "+": _addition,
    "-": _subtraction,
    "length": len,
    "0": 0,
    "1": 1,
    "2": 2,
    "3": 3,
    "4": 4,
    "5": 5,
    "range": _range,
    "map": _map,
    "iter": _miter,
    "append": lambda x: lambda l: l + [x],
    "unfold": _unfold,
    "index": _index,
    "fold": _fold,
    "is-mod": lambda x: lambda y: y % x == 0 if x != 0 else False,
    "mod": _mod,
    "is-prime": _isPrime,
    "is-square": _isSquare,
    "filter": lambda f: lambda l: [x for x in l if f(x)]
}
\end{lstlisting}

\clearpage
\subsection{Primitive Types}
\begin{lstlisting}[style=mypy, breaklines=true]
    primitive_types = {
    "empty": List(t0),
    "cons": Arrow(t0, Arrow(List(t0), List(t0))),
    "car": Arrow(List(t0), t0),
    "cdr": Arrow(List(t0), List(t0)),
    "empty?": Arrow(List(t0), BOOL),
    "max": Arrow(INT, Arrow(INT, INT)),
    "min": Arrow(INT, Arrow(INT, INT)),
    "gt?": Arrow(INT, Arrow(INT, BOOL)),
    "le?": Arrow(INT, Arrow(INT, BOOL)),
    "not": Arrow(BOOL, BOOL),
    "if": Arrow(BOOL, Arrow(t0, Arrow(t0, t0))),
    "eq?": Arrow(INT, Arrow(INT, BOOL)),
    "*": Arrow(INT, Arrow(INT, INT)),
    "+": Arrow(INT, Arrow(INT, INT)),
    "-": Arrow(INT, Arrow(INT, INT)),
    "length": Arrow(List(t0), INT),
    "0": INT,
    "1": INT,
    "2": INT,
    "3": INT,
    "4": INT,
    "5": INT,
    "range": Arrow(INT, List(INT)),
    "map": Arrow(Arrow(t0, t1), Arrow(List(t0), List(t1))),
    "iter": Arrow(INT, Arrow(Arrow(t0, t0), Arrow(t0, t0))),
    "append": Arrow(t0, Arrow(List(t0), List(t0))),
    "unfold": Arrow(t0, Arrow(Arrow(t0, BOOL), Arrow(Arrow(t0, t1), Arrow(Arrow(t0, t0), List(t1))))),
    "index": Arrow(INT, Arrow(List(t0), t0)),
    "fold": Arrow(List(t0), Arrow(t1, Arrow(Arrow(t0, Arrow(t1, t1)), t1))),
    "is-mod": Arrow(INT, Arrow(INT, BOOL)),
    "mod": Arrow(INT, Arrow(INT, INT)),
    "is-prime": Arrow(INT, BOOL),
    "is-square": Arrow(INT, BOOL),
    "filter": Arrow(Arrow(t0, BOOL), Arrow(List(t0), List(t0))),
}
\end{lstlisting}

\clearpage
\section{Model Parameters}
\begin{table}[h!]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
    \textbf{Class} & \textbf{Parameter} & \textbf{Value} \\
    \hline
    IOEncoder &  &  \\
     & size\_max & 10 \\
     & d\_model & 512 \\
    \hline
    RuleEncoder & & \\
     & d\_model & 512 \\
    \hline
    Generative Model &  & \\
     & d\_model & 512 \\
     & num\_heads & 8 \\
     & num\_layers & 2 \\
     & dropout & 0.1 \\
    \hline
    Forward Policy & & \\
    & d\_model & 512 \\
    & num\_layers & 2 \\
    & activation function & ReLU \\
    \hline
    Z & & \\
    & d\_model & 512 \\
    & num\_layers & 2 \\
    & activation function & ReLU \\
    \hline
    \end{tabular}
    \caption{Model Parameters}
    \label{table:params}
    \end{table}


    \subsection{Big experiment}

    \begin{table}[H]
        \centering
        \begin{tabular}{|l|l|}
        \hline
        \textbf{Variable} & \textbf{Value} \\
        \hline
        \texttt{d\_model} & 512 \\
        \hline
        \texttt{max\_program\_depth} & 4 \\
        \hline
        \texttt{shuffle\_tasks} & True \\
        \hline
        \texttt{n\_tasks} & 145 \\
        \hline
        \texttt{variable\_batch} & False \\
        \hline
        \texttt{train\_ratio} & 0.5 \\
        \hline
        \texttt{seed} & 3 \\
        \hline
        \texttt{n\_examples\_max} & (based on \texttt{data.nb\_examples\_max}) \\
        \hline
        \texttt{size\_max} & 10 \\
        \hline
        \texttt{lexicon} & (based on \texttt{data.lexicon}) \\
        \hline
        \texttt{cfg} & (based on \texttt{data.cfg}) \\
        \hline
        \texttt{num\_heads} & 8 \\
        \hline
        \texttt{num\_layers} & 2 \\
        \hline
        \texttt{dropout} & 0.1 \\
        \hline
        \texttt{min\_program\_depth} & (based on \texttt{data.max\_program\_depth}) \\
        \hline
        \texttt{max\_program\_depth} & (based on \texttt{data.max\_program\_depth}) \\
        \hline
        \texttt{epochs} & 5 \\
        \hline
        \texttt{batch\_size} & 4 \\
        \hline
        \texttt{learning\_rate\_gen} & $1 \times 10^{-4}$ \\
        \hline
        \texttt{learning\_rate\_pol} & $1 \times 10^{-4}$ \\
        \hline
        \texttt{e\_steps} & 2000 \\
        \hline
        \texttt{m\_step\_threshold\_init} & 150 \\
        \hline
        \texttt{m\_steps} & 2000 \\
        \hline
        \texttt{inference\_steps} & 100 \\
        \hline
        \texttt{alpha} & 0.3 \\
        \hline
        \texttt{beta} & 0.7 \\
        \hline
        \texttt{gamma} & 10 \\
        \hline
        \texttt{epsilon} & 0.3 \\
        \hline
        \texttt{replay\_prob} & 1 \\
        \hline
        \texttt{fantasy\_prob} & 1 \\
        \hline
        \texttt{data} & (based on \texttt{data}) \\
        \hline
        \texttt{model} & (based on \texttt{model}) \\
        \hline
        \texttt{save\_checkpoint} & (based on \texttt{save\_checkpoint}) \\
        \hline
    \end{tabular}
    \caption{Experiment Parameters}
    \label{}
\end{table}
    

\clearpage
\section{Formal Grammars}\label{app:cfg}

\textbf{Context-Free Grammars (CFGs)} are essential in defining the syntactical structures of many formal languages.
We can formalize the notion of CFGs as follows:

Let \( G = (N, \Sigma, P, S) \) be a Context-Free Grammar, where:

\begin{itemize}
    \item \( N \) is a finite set of non-terminal symbols.
    \item \( \Sigma \) is a finite set of terminal symbols with \newline \( N \cap \Sigma = \emptyset \)
    \item \( P \) is a finite set of production rules, where each rule is of the form \( N \rightarrow (N \cup \Sigma)^* \)
    \item \( S \) is the start symbol, with \( S \in N \)
\end{itemize}

Given such a CFG, the derived sentence space \( \Pi(G) \) is the set of all possible strings (or sequences of symbols) derivable from \( S \).

Given a Context-Free Grammar \( G \) and a defined objective function \( f \) that maps any program \( p \in \Pi(G) \) to a real value representing its desirability or fitness:

Find \( p^* \) such that:
\[ p^* = \arg\max_{p \in \Pi(G)} f(p) \]

In other words, the problem is to locate a program \( p^* \) within the vast program space \( \Pi(G) \) defined by \( G \) that maximizes (or, alternatively, minimizes) the objective function \( f \). \\

\noindent A \textbf{Probabilistic Context-Free Grammar (PCFG)} is an extension of a CFG \( G \), denoted as \( G' = (N, \Sigma, P', S) \), where:

\begin{itemize}
    \item \( N \) and \( \Sigma \) are as defined in the CFG.
    \item \( P' \) is a set of production rules, where each rule \( A \rightarrow \alpha \) is associated with a probability \( P(A \rightarrow \alpha) \), representing the likelihood of selecting that particular rule. These probabilities are subject to the condition that, for each non-terminal \( A \), the sum of probabilities for all rules \( A \rightarrow \alpha \) is equal to 1.
\end{itemize}


\clearpage
\section{Levenshtein Distance}\label{app:levenshtein}
Given two strings \( s \) and \( t \) of lengths \( m \) and \( n \) respectively, the Levenshtein distance \( d(s, t) \) is defined as the cost of the cheapest sequence of edits needed to transform \( s \) into \( t \). 
The Levenshtein distance can be efficiently computed using dynamic programming. The idea is to construct a matrix where each cell \( (i, j) \) represents the cost of transforming the first \( i \) characters of \( s \) into the first \( j \) characters of \( t \). 

The formula for filling in the matrix is:
\begin{enumerate}
    \item If \( i = 0 \), then \( d(i, j) = j \) (cost of adding \( j \) characters).
    \item If \( j = 0 \), then \( d(i, j) = i \) (cost of deleting \( i \) characters).
    \item Otherwise:   \[
        d(i, j) = \min \begin{cases} 
        d(i-1, j) + 1 \\ 
        d(i, j-1) + 1 \\ 
        d(i-1, j-1) + \text{cost}(s_i, t_j) 
        \end{cases}
        \]
        where \( \text{cost}(s_i, t_j) \) is 0 if \( s_i = t_j \) and 1 otherwise.
\end{enumerate}

The value of \( d(m, n) \) will then be the Levenshtein distance between \( s \) and \( t \).