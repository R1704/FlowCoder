\relax 
\providecommand\hyper@newdestlabel[2]{}
\abx@aux@refcontext{nty/global//global/global}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\@newglossary{acronym}{alg}{acr}{acn}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{master_thesis_s1000522.ist}
\@glsorder{word}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\abx@aux@cite{ullmanMindGamesGame2017}
\abx@aux@segm{0}{0}{ullmanMindGamesGame2017}
\abx@aux@cite{ullmanMindGamesGame2017}
\abx@aux@segm{0}{0}{ullmanMindGamesGame2017}
\abx@aux@cite{pearsonHumanImaginationCognitive2019}
\abx@aux@segm{0}{0}{pearsonHumanImaginationCognitive2019}
\abx@aux@cite{bengio2021deep}
\abx@aux@segm{0}{0}{bengio2021deep}
\abx@aux@cite{hofstadter2013surfaces}
\abx@aux@segm{0}{0}{hofstadter2013surfaces}
\abx@aux@cite{cholletMeasureIntelligence2019}
\abx@aux@segm{0}{0}{cholletMeasureIntelligence2019}
\abx@aux@cite{lecun2022path}
\abx@aux@segm{0}{0}{lecun2022path}
\abx@aux@cite{Fodor_Pylyshyn_1988}
\abx@aux@segm{0}{0}{Fodor_Pylyshyn_1988}
\abx@aux@cite{hofstadter2013surfaces}
\abx@aux@segm{0}{0}{hofstadter2013surfaces}
\abx@aux@cite{boicho2001analogical}
\abx@aux@segm{0}{0}{boicho2001analogical}
\abx@aux@cite{berwickPovertyStimulusRevisited2011}
\abx@aux@segm{0}{0}{berwickPovertyStimulusRevisited2011}
\abx@aux@cite{fristonWorldModelLearning2021}
\abx@aux@segm{0}{0}{fristonWorldModelLearning2021}
\abx@aux@cite{hintonHowRepresentPartwhole2021}
\abx@aux@segm{0}{0}{hintonHowRepresentPartwhole2021}
\abx@aux@cite{martinsHowChildrenPerceive2014}
\abx@aux@segm{0}{0}{martinsHowChildrenPerceive2014}
\abx@aux@cite{raussWhatBottomUpWhat2013}
\abx@aux@segm{0}{0}{raussWhatBottomUpWhat2013}
\abx@aux@cite{schwartzBehavioralNeuralConstraints2017}
\abx@aux@segm{0}{0}{schwartzBehavioralNeuralConstraints2017}
\abx@aux@cite{dehaeneSymbolsMentalPrograms2022}
\abx@aux@segm{0}{0}{dehaeneSymbolsMentalPrograms2022}
\abx@aux@cite{dehaeneSymbolsMentalPrograms2022}
\abx@aux@segm{0}{0}{dehaeneSymbolsMentalPrograms2022}
\abx@aux@cite{alroumiMentalCompressionSpatial2021}
\abx@aux@segm{0}{0}{alroumiMentalCompressionSpatial2021}
\abx@aux@cite{dehaeneSymbolsMentalPrograms2022}
\abx@aux@segm{0}{0}{dehaeneSymbolsMentalPrograms2022}
\abx@aux@cite{dehaeneSymbolsMentalPrograms2022}
\abx@aux@segm{0}{0}{dehaeneSymbolsMentalPrograms2022}
\abx@aux@cite{dehaeneSymbolsMentalPrograms2022}
\abx@aux@segm{0}{0}{dehaeneSymbolsMentalPrograms2022}
\abx@aux@cite{dehaeneSymbolsMentalPrograms2022}
\abx@aux@segm{0}{0}{dehaeneSymbolsMentalPrograms2022}
\abx@aux@cite{dehaeneSymbolsMentalPrograms2022}
\abx@aux@segm{0}{0}{dehaeneSymbolsMentalPrograms2022}
\abx@aux@cite{dehaeneSymbolsMentalPrograms2022}
\abx@aux@segm{0}{0}{dehaeneSymbolsMentalPrograms2022}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{6}{section.0.1}\protected@file@percent }
\abx@aux@backref{5}{ullmanMindGamesGame2017}{0}{6}{6}
\abx@aux@backref{6}{ullmanMindGamesGame2017}{0}{6}{6}
\abx@aux@backref{7}{pearsonHumanImaginationCognitive2019}{0}{6}{6}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Background}{6}{subsection.0.1.1}\protected@file@percent }
\abx@aux@backref{8}{bengio2021deep}{0}{6}{6}
\abx@aux@backref{9}{hofstadter2013surfaces}{0}{6}{6}
\abx@aux@backref{10}{boicho2001analogical}{0}{6}{6}
\abx@aux@backref{11}{cholletMeasureIntelligence2019}{0}{6}{6}
\abx@aux@backref{12}{Fodor_Pylyshyn_1988}{0}{6}{6}
\abx@aux@backref{13}{hofstadter2013surfaces}{0}{6}{6}
\abx@aux@backref{14}{lecun2022path}{0}{6}{6}
\abx@aux@backref{15}{berwickPovertyStimulusRevisited2011}{0}{6}{6}
\abx@aux@backref{16}{fristonWorldModelLearning2021}{0}{6}{6}
\abx@aux@backref{17}{hintonHowRepresentPartwhole2021}{0}{6}{6}
\abx@aux@backref{18}{martinsHowChildrenPerceive2014}{0}{6}{6}
\abx@aux@backref{19}{raussWhatBottomUpWhat2013}{0}{6}{6}
\abx@aux@backref{20}{schwartzBehavioralNeuralConstraints2017}{0}{6}{6}
\newlabel{subsubsec:pplot}{{1.1}{6}{Language of Thought}{section*.5}{}}
\abx@aux@backref{21}{dehaeneSymbolsMentalPrograms2022}{0}{6}{6}
\abx@aux@backref{22}{dehaeneSymbolsMentalPrograms2022}{0}{6}{6}
\abx@aux@backref{23}{alroumiMentalCompressionSpatial2021}{0}{6}{6}
\abx@aux@cite{lakeBuildingMachinesThat2017}
\abx@aux@segm{0}{0}{lakeBuildingMachinesThat2017}
\abx@aux@cite{ruleChildHacker2020}
\abx@aux@segm{0}{0}{ruleChildHacker2020}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Human cognition is underpinned by multiple mental \acrfullpl {dsl}. Each language has basic building blocks - primitives which can be programmatically composed to form more complex structures. \citet {dehaeneSymbolsMentalPrograms2022} distinguish between symmetric and asymmetric programming styles. The design principles of these mental languages are shared. They are symbolic, recursive, compositional, use formal grammar, and compress programs by adhering to the minimal description length principle. The diagram was taken from the original paper \cite {dehaeneSymbolsMentalPrograms2022}.\relax }}{7}{figure.caption.6}\protected@file@percent }
\abx@aux@backref{27}{dehaeneSymbolsMentalPrograms2022}{0}{7}{7}
\abx@aux@backref{28}{dehaeneSymbolsMentalPrograms2022}{0}{7}{7}
\abx@aux@backref{29}{dehaeneSymbolsMentalPrograms2022}{0}{7}{7}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:DSL}{{1}{7}{Human cognition is underpinned by multiple mental \acrfullpl {dsl}. Each language has basic building blocks - primitives which can be programmatically composed to form more complex structures. \citet {dehaeneSymbolsMentalPrograms2022} distinguish between symmetric and asymmetric programming styles. The design principles of these mental languages are shared. They are symbolic, recursive, compositional, use formal grammar, and compress programs by adhering to the minimal description length principle. The diagram was taken from the original paper \cite {dehaeneSymbolsMentalPrograms2022}.\relax }{figure.caption.6}{}}
\abx@aux@backref{30}{lakeBuildingMachinesThat2017}{0}{7}{7}
\abx@aux@backref{31}{ruleChildHacker2020}{0}{7}{7}
\abx@aux@cite{ellisDreamCoderBootstrappingInductive2021}
\abx@aux@segm{0}{0}{ellisDreamCoderBootstrappingInductive2021}
\abx@aux@cite{hinton1995wake}
\abx@aux@segm{0}{0}{hinton1995wake}
\abx@aux@cite{hinton1995wake}
\abx@aux@segm{0}{0}{hinton1995wake}
\abx@aux@cite{ellisDreamCoderBootstrappingInductive2021}
\abx@aux@segm{0}{0}{ellisDreamCoderBootstrappingInductive2021}
\abx@aux@cite{ellisDreamCoderBootstrappingInductive2021}
\abx@aux@segm{0}{0}{ellisDreamCoderBootstrappingInductive2021}
\newlabel{subsubsec:dreamcoder}{{1.1}{8}{DreamCoder}{section*.8}{}}
\abx@aux@backref{32}{ellisDreamCoderBootstrappingInductive2021}{0}{8}{8}
\abx@aux@backref{33}{hinton1995wake}{0}{8}{8}
\abx@aux@backref{34}{hinton1995wake}{0}{8}{8}
\abx@aux@cite{fijalkowScalingNeuralProgram2021}
\abx@aux@segm{0}{0}{fijalkowScalingNeuralProgram2021}
\abx@aux@cite{fijalkowScalingNeuralProgram2021}
\abx@aux@segm{0}{0}{fijalkowScalingNeuralProgram2021}
\abx@aux@cite{fijalkowScalingNeuralProgram2021}
\abx@aux@segm{0}{0}{fijalkowScalingNeuralProgram2021}
\abx@aux@cite{fijalkowScalingNeuralProgram2021}
\abx@aux@segm{0}{0}{fijalkowScalingNeuralProgram2021}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces (A) Tasks across eight distinct domains. (B) Illustration of the concept library that has been acquired. The left side displays the foundational primitives that are used to construct the concepts shown in the central area. To the right, a task is presented through input-output relationships alongside the derived solution. Below, this solution is reformulated using solely the initial primitives. Image taken with permission from the original paper \cite {ellisDreamCoderBootstrappingInductive2021}.\relax }}{9}{figure.caption.9}\protected@file@percent }
\abx@aux@backref{36}{ellisDreamCoderBootstrappingInductive2021}{0}{9}{9}
\newlabel{fig:conc_library}{{2}{9}{(A) Tasks across eight distinct domains. (B) Illustration of the concept library that has been acquired. The left side displays the foundational primitives that are used to construct the concepts shown in the central area. To the right, a task is presented through input-output relationships alongside the derived solution. Below, this solution is reformulated using solely the initial primitives. Image taken with permission from the original paper \cite {ellisDreamCoderBootstrappingInductive2021}.\relax }{figure.caption.9}{}}
\abx@aux@backref{37}{fijalkowScalingNeuralProgram2021}{0}{9}{9}
\abx@aux@backref{38}{fijalkowScalingNeuralProgram2021}{0}{9}{9}
\abx@aux@cite{kimCompoundProbabilisticContextFree2019}
\abx@aux@segm{0}{0}{kimCompoundProbabilisticContextFree2019}
\abx@aux@cite{kimCompoundProbabilisticContextFree2019}
\abx@aux@segm{0}{0}{kimCompoundProbabilisticContextFree2019}
\abx@aux@cite{vaswaniAttentionAllYou2017}
\abx@aux@segm{0}{0}{vaswaniAttentionAllYou2017}
\abx@aux@cite{vaswaniAttentionAllYou2017}
\abx@aux@segm{0}{0}{vaswaniAttentionAllYou2017}
\abx@aux@cite{wolfTransformersStateoftheArtNatural2020}
\abx@aux@segm{0}{0}{wolfTransformersStateoftheArtNatural2020}
\abx@aux@cite{khanTransformersVisionSurvey2022}
\abx@aux@segm{0}{0}{khanTransformersVisionSurvey2022}
\abx@aux@cite{wolfram2023chatgpt}
\abx@aux@segm{0}{0}{wolfram2023chatgpt}
\abx@aux@cite{bengioFlowNetworkBased2021}
\abx@aux@segm{0}{0}{bengioFlowNetworkBased2021}
\abx@aux@cite{bengioFlowNetworkBased2021}
\abx@aux@segm{0}{0}{bengioFlowNetworkBased2021}
\abx@aux@cite{bengioFlowNetworkBased2021}
\abx@aux@segm{0}{0}{bengioFlowNetworkBased2021}
\abx@aux@cite{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@segm{0}{0}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@cite{deleuBayesianStructureLearning2022}
\abx@aux@segm{0}{0}{deleuBayesianStructureLearning2022}
\abx@aux@backref{39}{fijalkowScalingNeuralProgram2021}{0}{10}{10}
\abx@aux@backref{40}{fijalkowScalingNeuralProgram2021}{0}{10}{10}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Limitations}{10}{subsection.0.1.2}\protected@file@percent }
\abx@aux@backref{41}{kimCompoundProbabilisticContextFree2019}{0}{10}{10}
\abx@aux@backref{42}{kimCompoundProbabilisticContextFree2019}{0}{10}{10}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Approach}{10}{subsection.0.1.3}\protected@file@percent }
\abx@aux@backref{43}{vaswaniAttentionAllYou2017}{0}{10}{10}
\abx@aux@backref{44}{vaswaniAttentionAllYou2017}{0}{10}{10}
\abx@aux@backref{45}{khanTransformersVisionSurvey2022}{0}{10}{10}
\abx@aux@backref{46}{wolfTransformersStateoftheArtNatural2020}{0}{10}{10}
\abx@aux@backref{47}{wolfram2023chatgpt}{0}{10}{10}
\abx@aux@backref{48}{bengioFlowNetworkBased2021}{0}{10}{10}
\abx@aux@backref{49}{bengioFlowNetworkBased2021}{0}{10}{10}
\abx@aux@backref{50}{bengioFlowNetworkBased2021}{0}{10}{10}
\abx@aux@backref{51}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}{0}{10}{10}
\abx@aux@backref{52}{deleuBayesianStructureLearning2022}{0}{10}{10}
\abx@aux@cite{sable-meyerLanguageThoughtMental2022}
\abx@aux@segm{0}{0}{sable-meyerLanguageThoughtMental2022}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Research Question, Aim, Motivation}{11}{subsection.0.1.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Scope and Limitations}{11}{subsection.0.1.5}\protected@file@percent }
\abx@aux@backref{53}{sable-meyerLanguageThoughtMental2022}{0}{11}{11}
\abx@aux@cite{bengioFlowNetworkBased2021}
\abx@aux@segm{0}{0}{bengioFlowNetworkBased2021}
\abx@aux@cite{malkinTrajectoryBalanceImproved2022}
\abx@aux@segm{0}{0}{malkinTrajectoryBalanceImproved2022}
\abx@aux@cite{malkinTrajectoryBalanceImproved2022}
\abx@aux@segm{0}{0}{malkinTrajectoryBalanceImproved2022}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{12}{section.0.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Foundations \& Computational Framework}{12}{subsection.0.2.1}\protected@file@percent }
\abx@aux@backref{54}{bengioFlowNetworkBased2021}{0}{12}{12}
\newlabel{eq:flow}{{1}{12}{\acrshort {gfn}}{equation.0.2.1}{}}
\newlabel{eq:flow_match}{{2}{12}{\acrshort {gfn}}{equation.0.2.2}{}}
\abx@aux@backref{55}{malkinTrajectoryBalanceImproved2022}{0}{12}{12}
\abx@aux@backref{56}{malkinTrajectoryBalanceImproved2022}{0}{12}{12}
\newlabel{form:TB}{{3}{12}{\acrshort {gfn}}{equation.0.2.3}{}}
\abx@aux@cite{han2022data}
\abx@aux@segm{0}{0}{han2022data}
\abx@aux@cite{ellisDreamCoderBootstrappingInductive2021}
\abx@aux@segm{0}{0}{ellisDreamCoderBootstrappingInductive2021}
\abx@aux@cite{kimCompoundProbabilisticContextFree2019}
\abx@aux@segm{0}{0}{kimCompoundProbabilisticContextFree2019}
\abx@aux@cite{kimCompoundProbabilisticContextFree2019}
\abx@aux@segm{0}{0}{kimCompoundProbabilisticContextFree2019}
\abx@aux@cite{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@segm{0}{0}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@cite{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@segm{0}{0}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@cite{kimCompoundProbabilisticContextFree2019}
\abx@aux@segm{0}{0}{kimCompoundProbabilisticContextFree2019}
\abx@aux@cite{kimCompoundProbabilisticContextFree2019}
\abx@aux@segm{0}{0}{kimCompoundProbabilisticContextFree2019}
\abx@aux@cite{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@segm{0}{0}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@cite{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@segm{0}{0}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@cite{hinton1995wake}
\abx@aux@segm{0}{0}{hinton1995wake}
\abx@aux@backref{57}{han2022data}{0}{13}{13}
\abx@aux@backref{58}{ellisDreamCoderBootstrappingInductive2021}{0}{13}{13}
\abx@aux@backref{59}{kimCompoundProbabilisticContextFree2019}{0}{13}{13}
\abx@aux@backref{60}{kimCompoundProbabilisticContextFree2019}{0}{13}{13}
\abx@aux@backref{61}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}{0}{13}{13}
\abx@aux@backref{62}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}{0}{13}{13}
\abx@aux@backref{63}{kimCompoundProbabilisticContextFree2019}{0}{13}{13}
\abx@aux@backref{64}{kimCompoundProbabilisticContextFree2019}{0}{13}{13}
\abx@aux@backref{65}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}{0}{13}{13}
\abx@aux@backref{66}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}{0}{13}{13}
\abx@aux@backref{67}{hinton1995wake}{0}{13}{13}
\abx@aux@cite{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@segm{0}{0}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@cite{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@segm{0}{0}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@cite{debruijnLambdaCalculusNotation1972}
\abx@aux@segm{0}{0}{debruijnLambdaCalculusNotation1972}
\abx@aux@cite{allamanis_learning_2018}
\abx@aux@segm{0}{0}{allamanis_learning_2018}
\abx@aux@cite{velickovicCLRSAlgorithmicReasoning2022}
\abx@aux@segm{0}{0}{velickovicCLRSAlgorithmicReasoning2022}
\abx@aux@cite{bieber_learning_2020}
\abx@aux@segm{0}{0}{bieber_learning_2020}
\abx@aux@cite{ibarz_generalist_2022}
\abx@aux@segm{0}{0}{ibarz_generalist_2022}
\abx@aux@cite{pengRethinkingPositionalEncoding2022}
\abx@aux@segm{0}{0}{pengRethinkingPositionalEncoding2022}
\abx@aux@cite{wang2017dynamic}
\abx@aux@segm{0}{0}{wang2017dynamic}
\abx@aux@cite{heTreesTransformersTheoretical2021}
\abx@aux@segm{0}{0}{heTreesTransformersTheoretical2021}
\abx@aux@cite{heTreesTransformersTheoretical2021}
\abx@aux@segm{0}{0}{heTreesTransformersTheoretical2021}
\abx@aux@cite{vaswaniAttentionAllYou2017}
\abx@aux@segm{0}{0}{vaswaniAttentionAllYou2017}
\abx@aux@backref{68}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}{0}{14}{14}
\abx@aux@backref{69}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}{0}{14}{14}
\newlabel{eq:threshold}{{6}{14}{Optimization Techniques}{equation.0.2.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}FlowCoder}{14}{subsection.0.2.2}\protected@file@percent }
\abx@aux@backref{70}{debruijnLambdaCalculusNotation1972}{0}{14}{14}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces An example of an abstract syntax tree (AST). This translates to the function \texttt  {f = var0 + var1 * var0}.\relax }}{14}{figure.caption.18}\protected@file@percent }
\newlabel{fig:AST}{{3}{14}{An example of an abstract syntax tree (AST). This translates to the function \texttt {f = var0 + var1 * var0}.\relax }{figure.caption.18}{}}
\newlabel{sec:gen_model}{{2.2}{14}{Generative Model}{section*.19}{}}
\abx@aux@backref{71}{allamanis_learning_2018}{0}{15}{15}
\abx@aux@backref{72}{bieber_learning_2020}{0}{15}{15}
\abx@aux@backref{73}{ibarz_generalist_2022}{0}{15}{15}
\abx@aux@backref{74}{velickovicCLRSAlgorithmicReasoning2022}{0}{15}{15}
\abx@aux@backref{75}{pengRethinkingPositionalEncoding2022}{0}{15}{15}
\abx@aux@backref{76}{wang2017dynamic}{0}{15}{15}
\abx@aux@backref{77}{heTreesTransformersTheoretical2021}{0}{15}{15}
\abx@aux@backref{78}{heTreesTransformersTheoretical2021}{0}{15}{15}
\abx@aux@backref{79}{vaswaniAttentionAllYou2017}{0}{15}{15}
\newlabel{sec:sampling_programs}{{2.2}{16}{Sampling Programs}{section*.22}{}}
\abx@aux@cite{bengioGFlowNetFoundations2023}
\abx@aux@segm{0}{0}{bengioGFlowNetFoundations2023}
\abx@aux@cite{bengioGFlowNetFoundations2023}
\abx@aux@segm{0}{0}{bengioGFlowNetFoundations2023}
\abx@aux@cite{Levenshtein}
\abx@aux@segm{0}{0}{Levenshtein}
\abx@aux@cite{fijalkowScalingNeuralProgram2021}
\abx@aux@segm{0}{0}{fijalkowScalingNeuralProgram2021}
\abx@aux@cite{fijalkowScalingNeuralProgram2021}
\abx@aux@segm{0}{0}{fijalkowScalingNeuralProgram2021}
\newlabel{sec:reward}{{2.2}{17}{Reward}{section*.23}{}}
\abx@aux@backref{80}{bengioGFlowNetFoundations2023}{0}{17}{17}
\abx@aux@backref{81}{bengioGFlowNetFoundations2023}{0}{17}{17}
\abx@aux@backref{82}{Levenshtein}{0}{17}{17}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Design}{17}{subsection.0.2.3}\protected@file@percent }
\newlabel{subsec:design}{{2.3}{17}{Design}{subsection.0.2.3}{}}
\abx@aux@backref{83}{fijalkowScalingNeuralProgram2021}{0}{17}{17}
\abx@aux@backref{84}{fijalkowScalingNeuralProgram2021}{0}{17}{17}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Syntactical Constraints\relax }}{18}{table.caption.24}\protected@file@percent }
\newlabel{tab:synconst}{{1}{18}{Syntactical Constraints\relax }{table.caption.24}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Task Examples\relax }}{18}{table.caption.25}\protected@file@percent }
\newlabel{tab:task_ex}{{2}{18}{Task Examples\relax }{table.caption.25}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Examples of tasks and programs solving the tasks.\relax }}{19}{table.caption.26}\protected@file@percent }
\newlabel{tab:task_programs}{{3}{19}{Examples of tasks and programs solving the tasks.\relax }{table.caption.26}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{19}{section.0.3}\protected@file@percent }
\newlabel{sec:results}{{3}{19}{Results}{section.0.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Experiment 1}{19}{subsection.0.3.1}\protected@file@percent }
\newlabel{sec:exp1}{{3.1}{19}{Experiment 1}{subsection.0.3.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Experiment 2}{19}{subsection.0.3.2}\protected@file@percent }
\newlabel{sec:exp2}{{3.2}{19}{Experiment 2}{subsection.0.3.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Bar plot of unique programs created per task. The sorted tasks the model has been trained are on the x-axis and the number of unique programs that have been created per task are on the y-axis. Bars of tasks that have been solved are coloured green and unsolved tasks are coloured red. The black dotted line demarcates the average number of uniquely created programs.\relax }}{20}{figure.caption.27}\protected@file@percent }
\newlabel{fig:program_variations_binary_train}{{4}{20}{Bar plot of unique programs created per task. The sorted tasks the model has been trained are on the x-axis and the number of unique programs that have been created per task are on the y-axis. Bars of tasks that have been solved are coloured green and unsolved tasks are coloured red. The black dotted line demarcates the average number of uniquely created programs.\relax }{figure.caption.27}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Distribution of unique solutions per task during inference, displayed in a log-scaled bar chart. The y-axis lists the task names, while the x-axis quantifies the number of unique solutions. The chart reveals that 13 tasks not solved in training were resolved during inference, with 11 belonging to groups with at least one task previously solved in training. Only solved tasks are shown.\relax }}{21}{figure.caption.28}\protected@file@percent }
\newlabel{fig:solution_variations_inference}{{5}{21}{Distribution of unique solutions per task during inference, displayed in a log-scaled bar chart. The y-axis lists the task names, while the x-axis quantifies the number of unique solutions. The chart reveals that 13 tasks not solved in training were resolved during inference, with 11 belonging to groups with at least one task previously solved in training. Only solved tasks are shown.\relax }{figure.caption.28}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Multiple found solutions.\relax }}{21}{table.caption.29}\protected@file@percent }
\newlabel{tab:multiple_solutions}{{4}{21}{Multiple found solutions.\relax }{table.caption.29}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Analysis of the minimum number of steps required to solve tasks during inference. The x-axis represents the number of steps, and the y-axis lists the task names, sorted by the number of steps taken to find a solution. The dotted line indicates the average number of steps needed. Tasks solved both during training and inference are highlighted in green, whereas tasks exclusively solved during inference are in purple. Only solved tasks are shown.\relax }}{22}{figure.caption.30}\protected@file@percent }
\newlabel{fig:plot_min_step_for_solution_inference}{{6}{22}{Analysis of the minimum number of steps required to solve tasks during inference. The x-axis represents the number of steps, and the y-axis lists the task names, sorted by the number of steps taken to find a solution. The dotted line indicates the average number of steps needed. Tasks solved both during training and inference are highlighted in green, whereas tasks exclusively solved during inference are in purple. Only solved tasks are shown.\relax }{figure.caption.30}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The plot displays the cumulative number of tasks solved (y-axis) against the number of steps (x-axis). Each step represents an iteration in the E-M cycle. The initial 2.000 steps correspond to the first E-step, marked with a blue background, followed by the first M-step spanning the next 2.000 steps (up to step 4.000), distinguished by a purple background. This pattern constitutes one complete epoch. The graph includes a dotted line representing the average number of tasks solved over all epochs, offering a benchmark for comparison. Furthermore, the intensity of the color hue in the plot encodes the temporal sequence of the epochs: brighter bars on the left signify earlier epochs (the first epoch), with the hue gradually darkening towards the right, culminating in the fifth and final epoch.\relax }}{23}{figure.caption.31}\protected@file@percent }
\newlabel{fig:em_cycles}{{7}{23}{The plot displays the cumulative number of tasks solved (y-axis) against the number of steps (x-axis). Each step represents an iteration in the E-M cycle. The initial 2.000 steps correspond to the first E-step, marked with a blue background, followed by the first M-step spanning the next 2.000 steps (up to step 4.000), distinguished by a purple background. This pattern constitutes one complete epoch. The graph includes a dotted line representing the average number of tasks solved over all epochs, offering a benchmark for comparison. Furthermore, the intensity of the color hue in the plot encodes the temporal sequence of the epochs: brighter bars on the left signify earlier epochs (the first epoch), with the hue gradually darkening towards the right, culminating in the fifth and final epoch.\relax }{figure.caption.31}{}}
\abx@aux@cite{bengioGFlowNetFoundations2023}
\abx@aux@segm{0}{0}{bengioGFlowNetFoundations2023}
\abx@aux@cite{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@segm{0}{0}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@cite{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@segm{0}{0}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{24}{section.0.4}\protected@file@percent }
\newlabel{sec:discussion}{{4}{24}{Discussion}{section.0.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}FlowCoder}{24}{subsection.0.4.1}\protected@file@percent }
\abx@aux@backref{85}{bengioGFlowNetFoundations2023}{0}{24}{24}
\abx@aux@backref{86}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}{0}{24}{24}
\abx@aux@backref{87}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}{0}{24}{24}
\abx@aux@cite{ellisDreamCoderBootstrappingInductive2021}
\abx@aux@segm{0}{0}{ellisDreamCoderBootstrappingInductive2021}
\abx@aux@cite{cernaAntiunificationGeneralizationSurvey2023}
\abx@aux@segm{0}{0}{cernaAntiunificationGeneralizationSurvey2023}
\abx@aux@cite{cernaAntiunificationGeneralizationSurvey2023}
\abx@aux@segm{0}{0}{cernaAntiunificationGeneralizationSurvey2023}
\abx@aux@cite{ellisDreamCoderBootstrappingInductive2021}
\abx@aux@segm{0}{0}{ellisDreamCoderBootstrappingInductive2021}
\abx@aux@cite{ellisDreamCoderBootstrappingInductive2021}
\abx@aux@segm{0}{0}{ellisDreamCoderBootstrappingInductive2021}
\abx@aux@cite{vanrooijTractableCognitionThesis2008}
\abx@aux@segm{0}{0}{vanrooijTractableCognitionThesis2008}
\abx@aux@cite{vanrooijTractableCognitionThesis2008}
\abx@aux@segm{0}{0}{vanrooijTractableCognitionThesis2008}
\abx@aux@cite{mairsonLinearLambdaCalculus}
\abx@aux@segm{0}{0}{mairsonLinearLambdaCalculus}
\abx@aux@cite{ruleChildHacker2020}
\abx@aux@segm{0}{0}{ruleChildHacker2020}
\abx@aux@cite{goyalInductiveBiasesDeep2022}
\abx@aux@segm{0}{0}{goyalInductiveBiasesDeep2022}
\abx@aux@cite{goyalInductiveBiasesDeep2022}
\abx@aux@segm{0}{0}{goyalInductiveBiasesDeep2022}
\newlabel{sec:MDL}{{4.1}{25}{Minimum Description Length}{section*.33}{}}
\abx@aux@backref{88}{ellisDreamCoderBootstrappingInductive2021}{0}{25}{25}
\abx@aux@backref{89}{cernaAntiunificationGeneralizationSurvey2023}{0}{25}{25}
\abx@aux@backref{90}{cernaAntiunificationGeneralizationSurvey2023}{0}{25}{25}
\abx@aux@backref{91}{ellisDreamCoderBootstrappingInductive2021}{0}{25}{25}
\abx@aux@backref{92}{ellisDreamCoderBootstrappingInductive2021}{0}{25}{25}
\abx@aux@backref{93}{vanrooijTractableCognitionThesis2008}{0}{25}{25}
\abx@aux@backref{94}{vanrooijTractableCognitionThesis2008}{0}{25}{25}
\abx@aux@cite{keles2022computational}
\abx@aux@segm{0}{0}{keles2022computational}
\abx@aux@cite{allamanis_learning_2018}
\abx@aux@segm{0}{0}{allamanis_learning_2018}
\abx@aux@cite{allamanis_learning_2018}
\abx@aux@segm{0}{0}{allamanis_learning_2018}
\abx@aux@cite{wang2017dynamic}
\abx@aux@segm{0}{0}{wang2017dynamic}
\abx@aux@cite{wang2017dynamic}
\abx@aux@segm{0}{0}{wang2017dynamic}
\abx@aux@cite{ibarz_generalist_2022}
\abx@aux@segm{0}{0}{ibarz_generalist_2022}
\abx@aux@cite{ibarz_generalist_2022}
\abx@aux@segm{0}{0}{ibarz_generalist_2022}
\abx@aux@cite{zhangNovelNeuralSource2019}
\abx@aux@segm{0}{0}{zhangNovelNeuralSource2019}
\abx@aux@cite{zhangNovelNeuralSource2019}
\abx@aux@segm{0}{0}{zhangNovelNeuralSource2019}
\abx@aux@cite{oliveiraAbstractSyntaxGraphs2013}
\abx@aux@segm{0}{0}{oliveiraAbstractSyntaxGraphs2013}
\abx@aux@cite{oliveiraAbstractSyntaxGraphs2013}
\abx@aux@segm{0}{0}{oliveiraAbstractSyntaxGraphs2013}
\abx@aux@cite{joshi2020transformers}
\abx@aux@segm{0}{0}{joshi2020transformers}
\abx@aux@cite{joshi2020transformers}
\abx@aux@segm{0}{0}{joshi2020transformers}
\abx@aux@cite{zhangHippocampalSpatialRepresentations2023}
\abx@aux@segm{0}{0}{zhangHippocampalSpatialRepresentations2023}
\abx@aux@cite{zhangHippocampalSpatialRepresentations2023}
\abx@aux@segm{0}{0}{zhangHippocampalSpatialRepresentations2023}
\abx@aux@cite{cetinHyperbolicDeepReinforcement2022}
\abx@aux@segm{0}{0}{cetinHyperbolicDeepReinforcement2022}
\abx@aux@cite{cetinHyperbolicDeepReinforcement2022}
\abx@aux@segm{0}{0}{cetinHyperbolicDeepReinforcement2022}
\abx@aux@cite{auyespekHyperbolicEmbeddingFinding}
\abx@aux@segm{0}{0}{auyespekHyperbolicEmbeddingFinding}
\abx@aux@cite{auyespekHyperbolicEmbeddingFinding}
\abx@aux@segm{0}{0}{auyespekHyperbolicEmbeddingFinding}
\abx@aux@cite{khanHyperbolicRepresentationsSource}
\abx@aux@segm{0}{0}{khanHyperbolicRepresentationsSource}
\abx@aux@cite{khanHyperbolicRepresentationsSource}
\abx@aux@segm{0}{0}{khanHyperbolicRepresentationsSource}
\abx@aux@cite{nickelPoincareEmbeddingsLearning2017}
\abx@aux@segm{0}{0}{nickelPoincareEmbeddingsLearning2017}
\abx@aux@cite{nickelPoincareEmbeddingsLearning2017}
\abx@aux@segm{0}{0}{nickelPoincareEmbeddingsLearning2017}
\abx@aux@cite{luHyperbolicFunctionEmbedding2019}
\abx@aux@segm{0}{0}{luHyperbolicFunctionEmbedding2019}
\abx@aux@cite{luHyperbolicFunctionEmbedding2019}
\abx@aux@segm{0}{0}{luHyperbolicFunctionEmbedding2019}
\newlabel{par:rules_type}{{4.1}{26}{Rules and Type Inference}{section*.35}{}}
\abx@aux@backref{95}{mairsonLinearLambdaCalculus}{0}{26}{26}
\abx@aux@backref{96}{ruleChildHacker2020}{0}{26}{26}
\abx@aux@backref{97}{goyalInductiveBiasesDeep2022}{0}{26}{26}
\abx@aux@backref{98}{goyalInductiveBiasesDeep2022}{0}{26}{26}
\abx@aux@backref{99}{keles2022computational}{0}{26}{26}
\abx@aux@backref{100}{allamanis_learning_2018}{0}{26}{26}
\abx@aux@backref{101}{allamanis_learning_2018}{0}{26}{26}
\abx@aux@backref{102}{wang2017dynamic}{0}{26}{26}
\abx@aux@backref{103}{wang2017dynamic}{0}{26}{26}
\abx@aux@backref{104}{ibarz_generalist_2022}{0}{26}{26}
\abx@aux@backref{105}{ibarz_generalist_2022}{0}{26}{26}
\abx@aux@backref{106}{zhangNovelNeuralSource2019}{0}{26}{26}
\abx@aux@backref{107}{zhangNovelNeuralSource2019}{0}{26}{26}
\abx@aux@backref{108}{oliveiraAbstractSyntaxGraphs2013}{0}{26}{26}
\abx@aux@backref{109}{oliveiraAbstractSyntaxGraphs2013}{0}{26}{26}
\abx@aux@backref{110}{joshi2020transformers}{0}{26}{26}
\abx@aux@backref{111}{joshi2020transformers}{0}{26}{26}
\abx@aux@backref{112}{zhangHippocampalSpatialRepresentations2023}{0}{26}{26}
\abx@aux@backref{113}{zhangHippocampalSpatialRepresentations2023}{0}{26}{26}
\abx@aux@backref{114}{cetinHyperbolicDeepReinforcement2022}{0}{26}{26}
\abx@aux@backref{115}{cetinHyperbolicDeepReinforcement2022}{0}{26}{26}
\abx@aux@backref{116}{auyespekHyperbolicEmbeddingFinding}{0}{26}{26}
\abx@aux@backref{117}{auyespekHyperbolicEmbeddingFinding}{0}{26}{26}
\abx@aux@backref{118}{khanHyperbolicRepresentationsSource}{0}{26}{26}
\abx@aux@backref{119}{khanHyperbolicRepresentationsSource}{0}{26}{26}
\abx@aux@backref{120}{nickelPoincareEmbeddingsLearning2017}{0}{26}{26}
\abx@aux@backref{121}{nickelPoincareEmbeddingsLearning2017}{0}{26}{26}
\abx@aux@backref{122}{luHyperbolicFunctionEmbedding2019}{0}{26}{26}
\abx@aux@backref{123}{luHyperbolicFunctionEmbedding2019}{0}{26}{26}
\abx@aux@cite{fijalkowScalingNeuralProgram2021}
\abx@aux@segm{0}{0}{fijalkowScalingNeuralProgram2021}
\abx@aux@cite{AndoniKO10}
\abx@aux@segm{0}{0}{AndoniKO10}
\abx@aux@cite{AndoniKO10}
\abx@aux@segm{0}{0}{AndoniKO10}
\abx@aux@cite{han2022data}
\abx@aux@segm{0}{0}{han2022data}
\abx@aux@cite{han2022data}
\abx@aux@segm{0}{0}{han2022data}
\abx@aux@cite{silverRewardEnough2021}
\abx@aux@segm{0}{0}{silverRewardEnough2021}
\abx@aux@cite{silverRewardEnough2021}
\abx@aux@segm{0}{0}{silverRewardEnough2021}
\abx@aux@cite{colasAutotelicAgentsIntrinsically2022}
\abx@aux@segm{0}{0}{colasAutotelicAgentsIntrinsically2022}
\abx@aux@cite{colasAutotelicAgentsIntrinsically2022}
\abx@aux@segm{0}{0}{colasAutotelicAgentsIntrinsically2022}
\abx@aux@cite{Juechems_Summerfield_2019}
\abx@aux@segm{0}{0}{Juechems_Summerfield_2019}
\abx@aux@cite{ruleChildHacker2020}
\abx@aux@segm{0}{0}{ruleChildHacker2020}
\abx@aux@cite{ruleChildHacker2020}
\abx@aux@segm{0}{0}{ruleChildHacker2020}
\abx@aux@backref{124}{fijalkowScalingNeuralProgram2021}{0}{27}{27}
\abx@aux@backref{125}{AndoniKO10}{0}{27}{27}
\abx@aux@backref{126}{AndoniKO10}{0}{27}{27}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}World Model}{27}{subsection.0.4.2}\protected@file@percent }
\abx@aux@backref{127}{han2022data}{0}{27}{27}
\abx@aux@backref{128}{han2022data}{0}{27}{27}
\abx@aux@cite{griffithsBayesianModelsCognition}
\abx@aux@segm{0}{0}{griffithsBayesianModelsCognition}
\abx@aux@cite{griffithsBayesianModelsCognition}
\abx@aux@segm{0}{0}{griffithsBayesianModelsCognition}
\abx@aux@cite{kimCompoundProbabilisticContextFree2019}
\abx@aux@segm{0}{0}{kimCompoundProbabilisticContextFree2019}
\abx@aux@cite{kimCompoundProbabilisticContextFree2019}
\abx@aux@segm{0}{0}{kimCompoundProbabilisticContextFree2019}
\abx@aux@cite{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@segm{0}{0}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}
\abx@aux@cite{gulwaniProgramSynthesis2017}
\abx@aux@segm{0}{0}{gulwaniProgramSynthesis2017}
\abx@aux@cite{gulwaniProgramSynthesis2017}
\abx@aux@segm{0}{0}{gulwaniProgramSynthesis2017}
\abx@aux@cite{lecunTutorialEnergyBasedLearning}
\abx@aux@segm{0}{0}{lecunTutorialEnergyBasedLearning}
\abx@aux@cite{hinton2002training}
\abx@aux@segm{0}{0}{hinton2002training}
\abx@aux@backref{129}{silverRewardEnough2021}{0}{28}{28}
\abx@aux@backref{130}{silverRewardEnough2021}{0}{28}{28}
\abx@aux@backref{131}{colasAutotelicAgentsIntrinsically2022}{0}{28}{28}
\abx@aux@backref{132}{colasAutotelicAgentsIntrinsically2022}{0}{28}{28}
\abx@aux@backref{133}{Juechems_Summerfield_2019}{0}{28}{28}
\abx@aux@backref{134}{ruleChildHacker2020}{0}{28}{28}
\abx@aux@backref{135}{ruleChildHacker2020}{0}{28}{28}
\abx@aux@backref{136}{griffithsBayesianModelsCognition}{0}{28}{28}
\abx@aux@backref{137}{griffithsBayesianModelsCognition}{0}{28}{28}
\abx@aux@backref{138}{kimCompoundProbabilisticContextFree2019}{0}{28}{28}
\abx@aux@backref{139}{kimCompoundProbabilisticContextFree2019}{0}{28}{28}
\abx@aux@backref{140}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}{0}{28}{28}
\abx@aux@backref{141}{gulwaniProgramSynthesis2017}{0}{28}{28}
\abx@aux@backref{142}{gulwaniProgramSynthesis2017}{0}{28}{28}
\abx@aux@backref{143}{lecunTutorialEnergyBasedLearning}{0}{28}{28}
\abx@aux@backref{144}{hinton2002training}{0}{28}{28}
\abx@aux@cite{Pouget_Beck_Ma_Latham_2013}
\abx@aux@segm{0}{0}{Pouget_Beck_Ma_Latham_2013}
\abx@aux@cite{Pouget_Beck_Ma_Latham_2013}
\abx@aux@segm{0}{0}{Pouget_Beck_Ma_Latham_2013}
\abx@aux@cite{bottemannePredictiveMindIntroduction2022}
\abx@aux@segm{0}{0}{bottemannePredictiveMindIntroduction2022}
\abx@aux@cite{caucheteuxEvidencePredictiveCoding2023}
\abx@aux@segm{0}{0}{caucheteuxEvidencePredictiveCoding2023}
\abx@aux@cite{mazzagliaFreeEnergyPrinciple2022}
\abx@aux@segm{0}{0}{mazzagliaFreeEnergyPrinciple2022}
\abx@aux@cite{kolb2001introduction}
\abx@aux@segm{0}{0}{kolb2001introduction}
\abx@aux@cite{silverCognitiveNeuroscienceFunctional2018}
\abx@aux@segm{0}{0}{silverCognitiveNeuroscienceFunctional2018}
\abx@aux@cite{Strick_Dum_Fiez_2009}
\abx@aux@segm{0}{0}{Strick_Dum_Fiez_2009}
\abx@aux@cite{Tee_Taylor_2019}
\abx@aux@segm{0}{0}{Tee_Taylor_2019}
\abx@aux@cite{Griffiths_Zhu_Grant_McCoy_2023}
\abx@aux@segm{0}{0}{Griffiths_Zhu_Grant_McCoy_2023}
\abx@aux@cite{Griffiths_Zhu_Grant_McCoy_2023}
\abx@aux@segm{0}{0}{Griffiths_Zhu_Grant_McCoy_2023}
\abx@aux@cite{marr1976understanding}
\abx@aux@segm{0}{0}{marr1976understanding}
\abx@aux@cite{marr1976understanding}
\abx@aux@segm{0}{0}{marr1976understanding}
\abx@aux@cite{dehaeneSymbolsMentalPrograms2022}
\abx@aux@segm{0}{0}{dehaeneSymbolsMentalPrograms2022}
\abx@aux@cite{liuDiscreteValuedNeuralCommunication2021}
\abx@aux@segm{0}{0}{liuDiscreteValuedNeuralCommunication2021}
\abx@aux@cite{lakeBuildingMachinesThat2017}
\abx@aux@segm{0}{0}{lakeBuildingMachinesThat2017}
\abx@aux@cite{pinker2003blank}
\abx@aux@segm{0}{0}{pinker2003blank}
\abx@aux@cite{ullmanMindGamesGame2017}
\abx@aux@segm{0}{0}{ullmanMindGamesGame2017}
\abx@aux@cite{ullmanTheoryLearningStochastic2012}
\abx@aux@segm{0}{0}{ullmanTheoryLearningStochastic2012}
\abx@aux@cite{dehaeneSymbolsMentalPrograms2022}
\abx@aux@segm{0}{0}{dehaeneSymbolsMentalPrograms2022}
\abx@aux@cite{windridgeRepresentationalFluidityEmbodied2018}
\abx@aux@segm{0}{0}{windridgeRepresentationalFluidityEmbodied2018}
\abx@aux@cite{garcezNeurosymbolicAI3rd2020}
\abx@aux@segm{0}{0}{garcezNeurosymbolicAI3rd2020}
\abx@aux@cite{garcezNeurosymbolicAI3rd2020}
\abx@aux@segm{0}{0}{garcezNeurosymbolicAI3rd2020}
\abx@aux@cite{piantadosiComputationalOriginRepresentation2021}
\abx@aux@segm{0}{0}{piantadosiComputationalOriginRepresentation2021}
\abx@aux@cite{piantadosiComputationalOriginRepresentation2021}
\abx@aux@segm{0}{0}{piantadosiComputationalOriginRepresentation2021}
\abx@aux@cite{piantadosiComputationalOriginRepresentation2021}
\abx@aux@segm{0}{0}{piantadosiComputationalOriginRepresentation2021}
\abx@aux@cite{piantadosiComputationalOriginRepresentation2021}
\abx@aux@segm{0}{0}{piantadosiComputationalOriginRepresentation2021}
\abx@aux@cite{doNeuralCircuitsSymbolic2021}
\abx@aux@segm{0}{0}{doNeuralCircuitsSymbolic2021}
\abx@aux@cite{doNeuralCircuitsSymbolic2021}
\abx@aux@segm{0}{0}{doNeuralCircuitsSymbolic2021}
\abx@aux@backref{145}{Pouget_Beck_Ma_Latham_2013}{0}{29}{29}
\abx@aux@backref{146}{Pouget_Beck_Ma_Latham_2013}{0}{29}{29}
\abx@aux@backref{147}{bottemannePredictiveMindIntroduction2022}{0}{29}{29}
\abx@aux@backref{148}{caucheteuxEvidencePredictiveCoding2023}{0}{29}{29}
\abx@aux@backref{149}{mazzagliaFreeEnergyPrinciple2022}{0}{29}{29}
\abx@aux@backref{150}{kolb2001introduction}{0}{29}{29}
\abx@aux@backref{151}{silverCognitiveNeuroscienceFunctional2018}{0}{29}{29}
\abx@aux@backref{152}{Strick_Dum_Fiez_2009}{0}{29}{29}
\abx@aux@backref{153}{Tee_Taylor_2019}{0}{29}{29}
\abx@aux@backref{154}{Griffiths_Zhu_Grant_McCoy_2023}{0}{29}{29}
\abx@aux@backref{155}{Griffiths_Zhu_Grant_McCoy_2023}{0}{29}{29}
\abx@aux@backref{156}{marr1976understanding}{0}{29}{29}
\abx@aux@backref{157}{marr1976understanding}{0}{29}{29}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Concepts}{29}{subsection.0.4.3}\protected@file@percent }
\abx@aux@cite{lakeBuildingMachinesThat2017}
\abx@aux@segm{0}{0}{lakeBuildingMachinesThat2017}
\abx@aux@cite{pearlTheoreticalImpedimentsMachine2018}
\abx@aux@segm{0}{0}{pearlTheoreticalImpedimentsMachine2018}
\abx@aux@cite{kicimanCausalReasoningLarge2023}
\abx@aux@segm{0}{0}{kicimanCausalReasoningLarge2023}
\abx@aux@cite{kicimanCausalReasoningLarge2023}
\abx@aux@segm{0}{0}{kicimanCausalReasoningLarge2023}
\abx@aux@cite{zecevicCausalParrotsLarge2023}
\abx@aux@segm{0}{0}{zecevicCausalParrotsLarge2023}
\abx@aux@cite{zecevicCausalParrotsLarge2023}
\abx@aux@segm{0}{0}{zecevicCausalParrotsLarge2023}
\abx@aux@cite{chaterProgramsCausalModels2013}
\abx@aux@segm{0}{0}{chaterProgramsCausalModels2013}
\abx@aux@cite{scholkopfCausalRepresentationLearning2021}
\abx@aux@segm{0}{0}{scholkopfCausalRepresentationLearning2021}
\abx@aux@backref{158}{dehaeneSymbolsMentalPrograms2022}{0}{30}{30}
\abx@aux@backref{159}{liuDiscreteValuedNeuralCommunication2021}{0}{30}{30}
\abx@aux@backref{160}{lakeBuildingMachinesThat2017}{0}{30}{30}
\abx@aux@backref{161}{pinker2003blank}{0}{30}{30}
\abx@aux@backref{162}{ullmanTheoryLearningStochastic2012}{0}{30}{30}
\abx@aux@backref{163}{ullmanMindGamesGame2017}{0}{30}{30}
\abx@aux@backref{164}{dehaeneSymbolsMentalPrograms2022}{0}{30}{30}
\abx@aux@backref{165}{windridgeRepresentationalFluidityEmbodied2018}{0}{30}{30}
\abx@aux@backref{166}{garcezNeurosymbolicAI3rd2020}{0}{30}{30}
\abx@aux@backref{167}{garcezNeurosymbolicAI3rd2020}{0}{30}{30}
\abx@aux@backref{168}{piantadosiComputationalOriginRepresentation2021}{0}{30}{30}
\abx@aux@backref{169}{piantadosiComputationalOriginRepresentation2021}{0}{30}{30}
\abx@aux@backref{170}{piantadosiComputationalOriginRepresentation2021}{0}{30}{30}
\abx@aux@backref{171}{piantadosiComputationalOriginRepresentation2021}{0}{30}{30}
\abx@aux@backref{172}{doNeuralCircuitsSymbolic2021}{0}{30}{30}
\abx@aux@backref{173}{doNeuralCircuitsSymbolic2021}{0}{30}{30}
\abx@aux@backref{174}{lakeBuildingMachinesThat2017}{0}{30}{30}
\abx@aux@backref{175}{pearlTheoreticalImpedimentsMachine2018}{0}{30}{30}
\abx@aux@backref{176}{kicimanCausalReasoningLarge2023}{0}{30}{30}
\abx@aux@backref{177}{kicimanCausalReasoningLarge2023}{0}{30}{30}
\abx@aux@cite{Kahneman11}
\abx@aux@segm{0}{0}{Kahneman11}
\abx@aux@cite{Kahneman11}
\abx@aux@segm{0}{0}{Kahneman11}
\abx@aux@cite{goyalInductiveBiasesDeep2022}
\abx@aux@segm{0}{0}{goyalInductiveBiasesDeep2022}
\abx@aux@cite{liuDiscreteValuedNeuralCommunication2021}
\abx@aux@segm{0}{0}{liuDiscreteValuedNeuralCommunication2021}
\abx@aux@cite{cartuyvelsDiscreteContinuousRepresentations2021}
\abx@aux@segm{0}{0}{cartuyvelsDiscreteContinuousRepresentations2021}
\abx@aux@cite{nyeImprovingCoherenceConsistency2021}
\abx@aux@segm{0}{0}{nyeImprovingCoherenceConsistency2021}
\abx@aux@cite{lecun2022path}
\abx@aux@segm{0}{0}{lecun2022path}
\abx@aux@cite{matsuoDeepLearningReinforcement2022}
\abx@aux@segm{0}{0}{matsuoDeepLearningReinforcement2022}
\abx@aux@cite{oliveiraAbstractSyntaxGraphs2013}
\abx@aux@segm{0}{0}{oliveiraAbstractSyntaxGraphs2013}
\abx@aux@cite{zhangNovelNeuralSource2019}
\abx@aux@segm{0}{0}{zhangNovelNeuralSource2019}
\abx@aux@cite{luHyperbolicFunctionEmbedding2019}
\abx@aux@segm{0}{0}{luHyperbolicFunctionEmbedding2019}
\abx@aux@cite{fijalkowScalingNeuralProgram2021}
\abx@aux@segm{0}{0}{fijalkowScalingNeuralProgram2021}
\abx@aux@cite{ellisDreamCoderBootstrappingInductive2021}
\abx@aux@segm{0}{0}{ellisDreamCoderBootstrappingInductive2021}
\abx@aux@backref{178}{zecevicCausalParrotsLarge2023}{0}{31}{31}
\abx@aux@backref{179}{zecevicCausalParrotsLarge2023}{0}{31}{31}
\abx@aux@backref{180}{chaterProgramsCausalModels2013}{0}{31}{31}
\abx@aux@backref{181}{scholkopfCausalRepresentationLearning2021}{0}{31}{31}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}System 1 \& System 2}{31}{subsection.0.4.4}\protected@file@percent }
\abx@aux@backref{182}{Kahneman11}{0}{31}{31}
\abx@aux@backref{183}{Kahneman11}{0}{31}{31}
\abx@aux@backref{184}{goyalInductiveBiasesDeep2022}{0}{31}{31}
\abx@aux@backref{185}{cartuyvelsDiscreteContinuousRepresentations2021}{0}{31}{31}
\abx@aux@backref{186}{lecun2022path}{0}{31}{31}
\abx@aux@backref{187}{liuDiscreteValuedNeuralCommunication2021}{0}{31}{31}
\abx@aux@backref{188}{matsuoDeepLearningReinforcement2022}{0}{31}{31}
\abx@aux@backref{189}{nyeImprovingCoherenceConsistency2021}{0}{31}{31}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Limitations \& Future Work}{31}{subsection.0.4.5}\protected@file@percent }
\abx@aux@backref{190}{oliveiraAbstractSyntaxGraphs2013}{0}{31}{31}
\abx@aux@backref{191}{zhangNovelNeuralSource2019}{0}{31}{31}
\abx@aux@backref{192}{luHyperbolicFunctionEmbedding2019}{0}{31}{31}
\abx@aux@backref{193}{fijalkowScalingNeuralProgram2021}{0}{31}{31}
\abx@aux@backref{194}{ellisDreamCoderBootstrappingInductive2021}{0}{32}{32}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{32}{section.0.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{Acronyms}{33}{section*.43}\protected@file@percent }
\abx@aux@cite{fijalkowScalingNeuralProgram2021}
\abx@aux@segm{0}{0}{fijalkowScalingNeuralProgram2021}
\abx@aux@cite{fijalkowScalingNeuralProgram2021}
\abx@aux@segm{0}{0}{fijalkowScalingNeuralProgram2021}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {A}Domain Specific Language (DSL)}{41}{appendix.A}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:dsl}{{A}{41}{Domain Specific Language (DSL)}{appendix.A}{}}
\abx@aux@backref{285}{fijalkowScalingNeuralProgram2021}{0}{41}{41}
\abx@aux@backref{286}{fijalkowScalingNeuralProgram2021}{0}{41}{41}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}Semantics}{41}{section.A.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Primitive Types}{43}{section.A.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {B}Experiment Hyperparameters}{44}{appendix.B}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:hyperparams}{{B}{44}{Experiment Hyperparameters}{appendix.B}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {B.1}{\ignorespaces Hyperparameters of both experiments.\relax }}{44}{table.caption.46}\protected@file@percent }
\newlabel{tab:hyperparams}{{B.1}{44}{Hyperparameters of both experiments.\relax }{table.caption.46}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {C}Model Parameters}{45}{appendix.C}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {C.1}{\ignorespaces Model Parameters\relax }}{45}{table.caption.47}\protected@file@percent }
\newlabel{table:params}{{C.1}{45}{Model Parameters\relax }{table.caption.47}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {D}Formal Grammars}{46}{appendix.D}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:cfg}{{D}{46}{Formal Grammars}{appendix.D}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {E}Levenshtein Distance}{47}{appendix.E}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:levenshtein}{{E}{47}{Levenshtein Distance}{appendix.E}{}}
\abx@aux@cite{malkin_trajectory_2022}
\abx@aux@segm{0}{0}{malkin_trajectory_2022}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {F}Trajectory Balance Loss}{48}{appendix.F}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:TB}{{F}{48}{Trajectory Balance Loss}{appendix.F}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {G}Variational Inference}{50}{appendix.G}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:vi}{{G}{50}{Variational Inference}{appendix.G}{}}
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{alroumiMentalCompressionSpatial2021}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{allamanis_learning_2018}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{AndoniKO10}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{auyespekHyperbolicEmbeddingFinding}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{bengioFlowNetworkBased2021}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{bengio2021deep}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{bengioGFlowNetFoundations2023}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{berwickPovertyStimulusRevisited2011}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{bieber_learning_2020}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{boicho2001analogical}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{bottemannePredictiveMindIntroduction2022}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{cartuyvelsDiscreteContinuousRepresentations2021}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{caucheteuxEvidencePredictiveCoding2023}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{cernaAntiunificationGeneralizationSurvey2023}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{cetinHyperbolicDeepReinforcement2022}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{chaterProgramsCausalModels2013}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{cholletMeasureIntelligence2019}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{colasAutotelicAgentsIntrinsically2022}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{garcezNeurosymbolicAI3rd2020}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{debruijnLambdaCalculusNotation1972}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{dehaeneSymbolsMentalPrograms2022}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{deleuBayesianStructureLearning2022}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{doNeuralCircuitsSymbolic2021}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{ellisDreamCoderBootstrappingInductive2021}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{fijalkowScalingNeuralProgram2021}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{Fodor_Pylyshyn_1988}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{fristonWorldModelLearning2021}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{goyalInductiveBiasesDeep2022}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{griffithsBayesianModelsCognition}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{Griffiths_Zhu_Grant_McCoy_2023}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{gulwaniProgramSynthesis2017}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{han2022data}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{heTreesTransformersTheoretical2021}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{hintonHowRepresentPartwhole2021}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{hinton2002training}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{hinton1995wake}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{hofstadter2013surfaces}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{Hu_Malkin_Jain_Everett_Graikos_Bengio_2023}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{ibarz_generalist_2022}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{joshi2020transformers}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{Juechems_Summerfield_2019}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{Kahneman11}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{keles2022computational}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{khanHyperbolicRepresentationsSource}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{khanTransformersVisionSurvey2022}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{kimCompoundProbabilisticContextFree2019}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{kicimanCausalReasoningLarge2023}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{kolb2001introduction}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{lakeBuildingMachinesThat2017}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{lecun2022path}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{lecunTutorialEnergyBasedLearning}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{Levenshtein}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{liuDiscreteValuedNeuralCommunication2021}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{luHyperbolicFunctionEmbedding2019}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{mairsonLinearLambdaCalculus}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{malkinTrajectoryBalanceImproved2022}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{marr1976understanding}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{martinsHowChildrenPerceive2014}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{matsuoDeepLearningReinforcement2022}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{mazzagliaFreeEnergyPrinciple2022}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{nickelPoincareEmbeddingsLearning2017}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{nyeImprovingCoherenceConsistency2021}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{oliveiraAbstractSyntaxGraphs2013}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{pearlTheoreticalImpedimentsMachine2018}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{pearsonHumanImaginationCognitive2019}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{pengRethinkingPositionalEncoding2022}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{piantadosiComputationalOriginRepresentation2021}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{pinker2003blank}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{Pouget_Beck_Ma_Latham_2013}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{raussWhatBottomUpWhat2013}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{ruleChildHacker2020}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{sable-meyerLanguageThoughtMental2022}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{scholkopfCausalRepresentationLearning2021}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{schwartzBehavioralNeuralConstraints2017}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{silverRewardEnough2021}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{silverCognitiveNeuroscienceFunctional2018}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{Strick_Dum_Fiez_2009}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{Tee_Taylor_2019}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{ullmanTheoryLearningStochastic2012}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{ullmanMindGamesGame2017}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{vanrooijTractableCognitionThesis2008}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{vaswaniAttentionAllYou2017}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{velickovicCLRSAlgorithmicReasoning2022}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{wang2017dynamic}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{windridgeRepresentationalFluidityEmbodied2018}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{wolfTransformersStateoftheArtNatural2020}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{wolfram2023chatgpt}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{zecevicCausalParrotsLarge2023}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{zhangHippocampalSpatialRepresentations2023}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{zhangNovelNeuralSource2019}{nty/global//global/global}
