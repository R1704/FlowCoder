\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\providecommand\@glsxtr@savepreloctag[2]{}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{master_thesis_s1000522.ist}
\@glsorder{word}
\citation{dehaene_symbols_2022}
\citation{ellis_dreamcoder_2021}
\citation{blouw2016concepts}
\@writefile{toc}{\contentsline {section}{\numberline {1}\leavevmode {\color  {orange}Introduction}}{6}{section.0.1}\protected@file@percent }
\citation{Ullman_Spelke_Battaglia_Tenenbaum_2017}
\citation{Lake_Ullman_Tenenbaum_Gershman_2017}
\citation{rule_child_2020}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}\leavevmode {\color  {orange}Main Contributions}}{7}{subsection.0.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}\leavevmode {\color  {orange}Cognition}}{7}{subsection.0.1.2}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ poverty of the stimulus. we learn from only a few observations. }{7}{section*.6}\protected@file@percent }
\pgfsyspdfmark {pgfid1}{19562754}{15872532}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}\leavevmode {\color  {green}World model}}{7}{subsubsection.0.1.2.1}\protected@file@percent }
\citation{friston_free-energy_2010}
\citation{friston_world_2021}
\citation{Lake_Ullman_Tenenbaum_Gershman_2017}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ Talk about intuitive physics and intuitive psychology or other research of human capabilities?}{8}{section*.7}\protected@file@percent }
\pgfsyspdfmark {pgfid2}{19562754}{29727474}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}\leavevmode {\color  {green}Bayesian Model}}{8}{subsubsection.0.1.2.2}\protected@file@percent }
\newlabel{form:bayes}{{1}{8}{\green {Bayesian Model}}{equation.0.1.1}{}}
\citation{Lake_Ullman_Tenenbaum_Gershman_2017}
\citation{Pearl_2018}
\citation{Pearl_2018}
\citation{burks1946peirce}
\citation{kwisthout2013most}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.3}\leavevmode {\color  {green}Compositionality}}{9}{subsubsection.0.1.2.3}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ should holarchies go here?}{9}{section*.8}\protected@file@percent }
\pgfsyspdfmark {pgfid3}{19562754}{39262053}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.4}\leavevmode {\color  {green}Causal Models}}{9}{subsubsection.0.1.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.5}\leavevmode {\color  {green}Abduction}}{9}{subsubsection.0.1.2.5}\protected@file@percent }
\citation{Ramstead_Kirchhoff_Friston_2020}
\citation{Kahneman11}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.6}\leavevmode {\color  {green}Varied Representations}}{10}{subsubsection.0.1.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.7}\leavevmode {\color  {green}System 1 \& System 2}}{10}{subsubsection.0.1.2.7}\protected@file@percent }
\citation{blouw2016concepts}
\citation{ball2013surfaces}
\citation{wolfram2023chatgpt}
\citation{Vaswani_Shazeer_Parmar_Uszkoreit_Jones_Gomez_Kaiser_Polosukhin_2017}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.8}\leavevmode {\color  {green}Concepts}}{11}{subsubsection.0.1.2.8}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ need sources for all of these}{11}{section*.9}\protected@file@percent }
\pgfsyspdfmark {pgfid4}{19562754}{17702988}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.9}\leavevmode {\color  {green}Large Language Models}}{11}{subsubsection.0.1.2.9}\protected@file@percent }
\newlabel{sec:llm}{{1.2.9}{11}{\green {Large Language Models}}{subsubsection.0.1.2.9}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ This should be Concept Space not LLMs}{11}{section*.10}\protected@file@percent }
\pgfsyspdfmark {pgfid5}{19562754}{12217539}
\citation{dehaene_symbols_2022}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces taken from google}}{12}{figure.0.1}\protected@file@percent }
\newlabel{fig:emb_space}{{1}{12}{taken from google}{figure.0.1}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ Explain the figure, explain vector space, dot product, etc.}{12}{section*.11}\protected@file@percent }
\pgfsyspdfmark {pgfid6}{19562754}{11453918}
\citation{dehaene_symbols_2022}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.10}\leavevmode {\color  {green}Probabilistic Programming}}{13}{subsubsection.0.1.2.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Image from \cite  {dehaene_symbols_2022}.}}{13}{figure.0.2}\protected@file@percent }
\newlabel{fig:DSL}{{2}{13}{Image from \cite {dehaene_symbols_2022}}{figure.0.2}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ Explain figure}{13}{section*.12}\protected@file@percent }
\pgfsyspdfmark {pgfid7}{19562754}{12150960}
\citation{lake_building_2016}
\citation{garcez_neurosymbolic_2020}
\citation{Lake_Ullman_Tenenbaum_Gershman_2017}
\citation{ellis_dreamcoder_2021}
\citation{hinton1995wake}
\citation{Ellis_Wong_Nye_Sable-Meyer_Cary_Morales_Hewitt_Solar-Lezama_Tenenbaum}
\citation{ellis_dreamcoder_2021}
\citation{ellis_dreamcoder_2021}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ child as a hacker}{14}{section*.13}\protected@file@percent }
\pgfsyspdfmark {pgfid8}{19562754}{36636061}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}\leavevmode {\color  {red}Background}}{14}{subsection.0.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}\leavevmode {\color  {green}DreamCoder}}{14}{subsubsection.0.1.3.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ explain typed lambda calculus See on the representation and learning of concepts(Morales) }{14}{section*.14}\protected@file@percent }
\pgfsyspdfmark {pgfid9}{19562754}{8966225}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces (A) 8 different domains of tasks. (B) Representation of the learned library of concepts. On the left we see the initial primitives from which the concepts in the middle region are composed. On the right we see a task as input-output relations and the found solution. On the bottom is the same solution expressed only with initial primitives. Image taken with permission from the original paper \cite  {ellis_dreamcoder_2021}.}}{15}{figure.0.3}\protected@file@percent }
\newlabel{fig:conc_library}{{3}{15}{(A) 8 different domains of tasks. (B) Representation of the learned library of concepts. On the left we see the initial primitives from which the concepts in the middle region are composed. On the right we see a task as input-output relations and the found solution. On the bottom is the same solution expressed only with initial primitives. Image taken with permission from the original paper \cite {ellis_dreamcoder_2021}}{figure.0.3}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ whats the last term in the above formula?}{15}{section*.15}\protected@file@percent }
\pgfsyspdfmark {pgfid10}{19562754}{19212915}
\citation{fijalkow_scaling_2021}
\citation{bengio_flow_2021}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}\leavevmode {\color  {green}DeepSynth}}{16}{subsubsection.0.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.3}\leavevmode {\color  {green}GFlowNet}}{16}{subsubsection.0.1.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}\leavevmode {\color  {red}Aim}}{17}{subsection.0.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}\leavevmode {\color  {green}Methods}}{17}{section.0.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}\leavevmode {\color  {green}FlowCoder}}{17}{subsection.0.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}\leavevmode {\color  {green}DeepSynth Framework}}{17}{subsubsection.0.2.1.1}\protected@file@percent }
\citation{bengio2023gflownet}
\citation{bengio_flow_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces An example of an abstract syntax tree (AST) using deBruijn indexing. This translates to \texttt  {var0 + var1 * var0}.}}{18}{figure.0.4}\protected@file@percent }
\newlabel{fig:AST}{{4}{18}{An example of an abstract syntax tree (AST) using deBruijn indexing. This translates to \texttt {var0 + var1 * var0}}{figure.0.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}\leavevmode {\color  {green}GFlowNet}}{18}{subsubsection.0.2.1.2}\protected@file@percent }
\newlabel{sec:gflownet}{{2.1.2}{18}{\green {GFlowNet}}{subsubsection.0.2.1.2}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ should this be here or in intro? Explain why we explain this. 1. to show how the algorithm works, 2. to show how we deal with the marginalisation term}{18}{section*.16}\protected@file@percent }
\pgfsyspdfmark {pgfid12}{19562754}{17589581}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ show diagram of DAG and talk about the causality requirement! (In the methods section we explain what we do and why we do it.)}{18}{section*.17}\protected@file@percent }
\pgfsyspdfmark {pgfid13}{19562754}{12324856}
\citation{malkin_trajectory_2022}
\newlabel{eq:flow}{{3}{19}{\green {GFlowNet}}{equation.0.2.3}{}}
\newlabel{eq:flow_match}{{4}{19}{\green {GFlowNet}}{equation.0.2.4}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ this is explained in a later section}{19}{section*.18}\protected@file@percent }
\pgfsyspdfmark {pgfid14}{19562754}{6448774}
\citation{hu_gflownet-em_2023}
\newlabel{form:TB}{{10}{20}{\green {GFlowNet}}{equation.0.2.10}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ We need to formalise the overall objective}{20}{section*.19}\protected@file@percent }
\pgfsyspdfmark {pgfid15}{19562754}{40897713}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}\leavevmode {\color  {green}Expectation-Maximisation}}{20}{subsubsection.0.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}\leavevmode {\color  {green}Sleep}}{20}{subsubsection.0.2.1.4}\protected@file@percent }
\citation{hu_gflownet-em_2023}
\citation{kim_compound_2019}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ filtering out programs that produce None, constants, etc. }{21}{section*.20}\protected@file@percent }
\pgfsyspdfmark {pgfid16}{20381955}{44463484}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5}\leavevmode {\color  {green}Optimisation Techniques}}{21}{subsubsection.0.2.1.5}\protected@file@percent }
\newlabel{sec:optim}{{2.1.5}{21}{\green {Optimisation Techniques}}{subsubsection.0.2.1.5}{}}
\newlabel{eq:threshold}{{13}{21}{\green {Optimisation Techniques}}{equation.0.2.13}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces FlowCoder}}{21}{algorithm.1}\protected@file@percent }
\newlabel{alg:flowcoder}{{1}{21}{\green {Optimisation Techniques}}{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}\leavevmode {\color  {green}Parameterisation}}{21}{subsection.0.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}\leavevmode {\color  {orange}Generative Model}}{21}{subsubsection.0.2.2.1}\protected@file@percent }
\citation{fijalkow_scaling_2021}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}\leavevmode {\color  {green}Forward Policy}}{22}{subsubsection.0.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}\leavevmode {\color  {green}Partition Function}}{22}{subsubsection.0.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}\leavevmode {\color  {green}IOEncoder}}{23}{subsubsection.0.2.2.4}\protected@file@percent }
\newlabel{sec:ioencoder}{{2.2.4}{23}{\green {IOEncoder}}{subsubsection.0.2.2.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5}\leavevmode {\color  {green}RuleEncoder}}{23}{subsubsection.0.2.2.5}\protected@file@percent }
\newlabel{sec:ruleencoder}{{2.2.5}{23}{\green {RuleEncoder}}{subsubsection.0.2.2.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.6}\leavevmode {\color  {orange}Sampling Programs}}{23}{subsubsection.0.2.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}\leavevmode {\color  {red}credit assignment}}{24}{subsection.0.2.3}\protected@file@percent }
\newlabel{sec:credit}{{2.3}{24}{\red {credit assignment}}{subsection.0.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}\leavevmode {\color  {green}Reward}}{24}{subsubsection.0.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}\leavevmode {\color  {red}reward}}{24}{subsection.0.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}\leavevmode {\color  {green}Design}}{25}{subsection.0.2.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Syntactical Constraints}}{25}{table.0.1}\protected@file@percent }
\newlabel{tab:synconst}{{1}{25}{Syntactical Constraints}{table.0.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Task Examples}}{26}{table.0.2}\protected@file@percent }
\newlabel{tab:task_ex}{{2}{26}{Task Examples}{table.0.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Examples of tasks and programs solving the tasks.}}{26}{table.0.3}\protected@file@percent }
\newlabel{tab:task_programs}{{3}{26}{Examples of tasks and programs solving the tasks}{table.0.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\leavevmode {\color  {green}Results}}{27}{section.0.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\leavevmode {\color  {green}Training}}{27}{subsection.0.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Bar plot of unique programs created per task. The sorted tasks the model has been trained are on the x-axis and the number of unique programs that have been created per task are on the y-axis. Bars of tasks that have been solved are coloured green and unsolved tasks are coloured red. The black dotted line demarcates the average number of uniquely created programs.}}{27}{figure.0.5}\protected@file@percent }
\newlabel{fig:program_variations_binary_train}{{5}{27}{Bar plot of unique programs created per task. The sorted tasks the model has been trained are on the x-axis and the number of unique programs that have been created per task are on the y-axis. Bars of tasks that have been solved are coloured green and unsolved tasks are coloured red. The black dotted line demarcates the average number of uniquely created programs}{figure.0.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The plot displays the cumulative number of tasks solved (y-axis) against the number of steps (x-axis). Each step represents an iteration in the E-M cycle. The initial 2.000 steps correspond to the first E-step, marked with a blue background, followed by the first M-step spanning the next 2.000 steps (up to step 4.000), distinguished by a purple background. This pattern constitutes one complete epoch. The graph includes a dotted line representing the average number of tasks solved over all epochs, offering a benchmark for comparison. Furthermore, the intensity of the color hue in the plot encodes the temporal sequence of the epochs: brighter bars on the left signify earlier epochs (the first epoch), with the hue gradually darkening towards the right, culminating in the fifth and final epoch.}}{28}{figure.0.6}\protected@file@percent }
\newlabel{fig:em_cycles}{{6}{28}{The plot displays the cumulative number of tasks solved (y-axis) against the number of steps (x-axis). Each step represents an iteration in the E-M cycle. The initial 2.000 steps correspond to the first E-step, marked with a blue background, followed by the first M-step spanning the next 2.000 steps (up to step 4.000), distinguished by a purple background. This pattern constitutes one complete epoch. The graph includes a dotted line representing the average number of tasks solved over all epochs, offering a benchmark for comparison. Furthermore, the intensity of the color hue in the plot encodes the temporal sequence of the epochs: brighter bars on the left signify earlier epochs (the first epoch), with the hue gradually darkening towards the right, culminating in the fifth and final epoch}{figure.0.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\leavevmode {\color  {green}Inference}}{28}{subsection.0.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Analysis of the number of unique programs generated per task during inference, as shown in Figure \ref  {fig:program_variations_binary_inference}. Tasks are listed on the x-axis, and the count of unique programs is on the y-axis. The figure highlights the variance in program generation across tasks, with \texttt  {caesar} tasks often showing limited program diversity, in contrast to other tasks that exhibit a wide range of attempts. The average number of unique programs created per task is approximately 145, indicating varied program attempts.}}{29}{figure.0.7}\protected@file@percent }
\newlabel{fig:program_variations_binary_inference}{{7}{29}{Analysis of the number of unique programs generated per task during inference, as shown in Figure \ref {fig:program_variations_binary_inference}. Tasks are listed on the x-axis, and the count of unique programs is on the y-axis. The figure highlights the variance in program generation across tasks, with \texttt {caesar} tasks often showing limited program diversity, in contrast to other tasks that exhibit a wide range of attempts. The average number of unique programs created per task is approximately 145, indicating varied program attempts}{figure.0.7}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ maybe take this plot out?}{29}{section*.21}\protected@file@percent }
\pgfsyspdfmark {pgfid17}{19562754}{23467008}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Distribution of unique solutions per task during inference, displayed in a log-scaled bar chart. The y-axis lists the task names, while the x-axis quantifies the number of unique solutions. The chart reveals that 13 tasks not solved in training were resolved during inference, with 11 belonging to groups with at least one task previously solved in training. Only solved tasks are shown.}}{30}{figure.0.8}\protected@file@percent }
\newlabel{fig:solution_variations_inference}{{8}{30}{Distribution of unique solutions per task during inference, displayed in a log-scaled bar chart. The y-axis lists the task names, while the x-axis quantifies the number of unique solutions. The chart reveals that 13 tasks not solved in training were resolved during inference, with 11 belonging to groups with at least one task previously solved in training. Only solved tasks are shown}{figure.0.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Multiple found solutions.}}{30}{table.0.4}\protected@file@percent }
\newlabel{tab:multiple_solutions}{{4}{30}{Multiple found solutions}{table.0.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Analysis of the minimum number of steps required to solve tasks during inference. The x-axis represents the number of steps, and the y-axis lists the task names, sorted by the number of steps taken to find a solution. The dotted line indicates the average number of steps needed. Tasks solved both during training and inference are highlighted in green, whereas tasks exclusively solved during inference are in purple. Only solved tasks are shown.}}{31}{figure.0.9}\protected@file@percent }
\newlabel{fig:plot_min_step_for_solution_inference}{{9}{31}{Analysis of the minimum number of steps required to solve tasks during inference. The x-axis represents the number of steps, and the y-axis lists the task names, sorted by the number of steps taken to find a solution. The dotted line indicates the average number of steps needed. Tasks solved both during training and inference are highlighted in green, whereas tasks exclusively solved during inference are in purple. Only solved tasks are shown}{figure.0.9}{}}
\citation{fijalkow_scaling_2021}
\@writefile{toc}{\contentsline {section}{\numberline {4}\leavevmode {\color  {orange}Discussion}}{32}{section.0.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\leavevmode {\color  {orange}Comparison to DreamCoder}}{33}{subsection.0.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\leavevmode {\color  {orange}Speed}}{33}{subsection.0.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}\leavevmode {\color  {green}Scaling the Model}}{34}{subsection.0.4.3}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ check this, check what is necessary}{34}{section*.22}\protected@file@percent }
\pgfsyspdfmark {pgfid18}{19562754}{47956497}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Scaling}{34}{subsubsection.0.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}\leavevmode {\color  {orange}program representation}}{35}{subsection.0.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}\leavevmode {\color  {red}program space}}{35}{subsection.0.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}\leavevmode {\color  {red}Limitations}}{36}{subsection.0.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}\leavevmode {\color  {red}Future Work}}{36}{subsection.0.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.1}\leavevmode {\color  {orange}Comparison to other approaches}}{36}{subsubsection.0.4.7.1}\protected@file@percent }
\citation{ullman_theory_2012}
\citation{gulwani_program_2017}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ should the above be in the intro??}{37}{section*.23}\protected@file@percent }
\pgfsyspdfmark {pgfid19}{19562754}{25888157}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.2}\leavevmode {\color  {red}Biological Plausibility}}{37}{subsubsection.0.4.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}\leavevmode {\color  {red}Conclusion}}{37}{subsection.0.4.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Creation of trees showing the construction process.}}{38}{figure.0.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Insert explanation + maybe change task to an actual task; same with state; maybe also show the forward and Z output better.}}{38}{figure.0.11}\protected@file@percent }
\newlabel{ref:model_diagram}{{11}{38}{Insert explanation + maybe change task to an actual task; same with state; maybe also show the forward and Z output better}{figure.0.11}{}}
\citation{sep-leibniz-logic-influence}
\citation{sep-language-thought}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Philosophical Ramifications}{39}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1}\leavevmode {\color  {orange}Language of Thought}}{39}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}\leavevmode {\color  {red}What is a Symbol? - Semiotics}}{39}{subsection.1.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}\leavevmode {\color  {orange}Semiotics}}{40}{subsection.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}\leavevmode {\color  {orange}Formal Grammar}}{40}{subsection.1.1.3}\protected@file@percent }
\citation{sep-goedel-incompleteness}
\citation{JCopeland2004-JCOTET}
\citation{chomsky1959certain}
\citation{dehaene_symbols_2022}
\citation{dehaene_symbols_2022}
\citation{rule_child_2020}
\citation{al_roumi_mental_2021}
\citation{dehaene_symbols_2022}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{cyan}{}{cyan!25}{\leavevmode {\color  {cyan!25}o}}\ Determining if a context-free grammar generates all possible strings, or if it is ambiguous. Given two context-free grammars, determining whether they generate the same set of strings, or whether one generates a subset of the strings generated by the other, or whether there is any string at all that both generate.}{41}{section*.24}\protected@file@percent }
\pgfsyspdfmark {pgfid22}{20381955}{46797516}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}\leavevmode {\color  {red}Incompleteness Theorem}}{41}{subsection.1.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}\leavevmode {\color  {red}Chomsky's Hierarchy}}{41}{subsection.1.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}\leavevmode {\color  {orange}What is Truth?}}{41}{section.1.2}\protected@file@percent }
\citation{garcez2020neurosymbolic}
\citation{Blank_2023}
\citation{piantadosi2021computational}
\citation{piantasodi2022meaning}
\citation{do2021neural}
\citation{santoro2021symbolic}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}\leavevmode {\color  {red}Where do the symbols/ primitives come from?}}{42}{subsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}\leavevmode {\color  {green}Neurosymbolic AI}}{42}{subsubsection.1.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}\leavevmode {\color  {red}Variable Binding}}{42}{subsubsection.1.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}\leavevmode {\color  {orange}What is Meaning?}}{42}{section.1.3}\protected@file@percent }
\citation{ellis_dreamcoder_2021}
\citation{santoro2021symbolic}
\citation{hofstadter_gdel_1979}
\citation{garcez2020neurosymbolic}
\citation{garcez2020neurosymbolic}
\citation{blokpoel2018deep}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{Plum}{}{Plum!25}{\leavevmode {\color  {Plum!25}o}}\ difference between what is meaning and what is meaningful, maps of meaning. what is meaningful is what guides you. its a gradient, a heuristic. Show studies that deeper understanding improves memory and meaning.}{43}{section*.25}\protected@file@percent }
\pgfsyspdfmark {pgfid23}{19562754}{39557874}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.0.1}\leavevmode {\color  {green}Poverty of the Stimulus}}{43}{subsubsection.1.3.0.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ should this be here?}{43}{section*.26}\protected@file@percent }
\pgfsyspdfmark {pgfid24}{19562754}{23258985}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\leavevmode {\color  {orange}Abduction}}{43}{subsection.1.3.1}\protected@file@percent }
\citation{blokpoel2018deep}
\citation{fodor1983modularity}
\citation{lewis2018memory}
\citation{blokpoel2018deep}
\citation{gentner1983structure}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}\leavevmode {\color  {green}Abduction Proper}}{44}{subsubsection.1.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.1.1.1}\leavevmode {\color  {green}Isotropy}}{44}{paragraph.1.3.1.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.1.1.2}\leavevmode {\color  {green}Open-endedness}}{44}{paragraph.1.3.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.1.1.3}\leavevmode {\color  {green}Novelty}}{44}{paragraph.1.3.1.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.1.1.4}\leavevmode {\color  {green}Groundedness}}{44}{paragraph.1.3.1.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.1.1.5}\leavevmode {\color  {green}Sensibility}}{44}{paragraph.1.3.1.1.5}\protected@file@percent }
\citation{haselager1997}
\citation{palmer1978fundamental}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.1.1.6}\leavevmode {\color  {green}Psychological realism}}{45}{paragraph.1.3.1.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.1.1.7}\leavevmode {\color  {green}Computational tractability}}{45}{paragraph.1.3.1.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}\leavevmode {\color  {green}Inference to the Best Explanation}}{45}{subsubsection.1.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.1.2.1}\leavevmode {\color  {green}Representation}}{45}{paragraph.1.3.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.1.2.2}\leavevmode {\color  {green}Inference}}{46}{paragraph.1.3.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\leavevmode {\color  {red}Subsymbolic Parse Trees}}{46}{subsection.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}\leavevmode {\color  {orange}What Is a Computation?}}{47}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\leavevmode {\color  {orange}Computational Mind}}{47}{subsection.1.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}\leavevmode {\color  {orange}What is a thought?}}{47}{section.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}\leavevmode {\color  {orange}What Does It Mean to Understand?}}{48}{section.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.0.1}\leavevmode {\color  {red}Operationalising "Understanding"}}{48}{subsubsection.1.6.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}\leavevmode {\color  {orange}What is a Concept?}}{48}{section.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}\leavevmode {\color  {red}Identity and Essence}}{48}{subsection.1.7.1}\protected@file@percent }
\citation{zeithamova_brain_2019}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1}\leavevmode {\color  {orange}Categories}}{49}{subsubsection.1.7.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.2}\leavevmode {\color  {orange}Computational models of categorization}}{49}{subsubsection.1.7.1.2}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{Plum}{}{Plum!25}{\leavevmode {\color  {Plum!25}o}}\ relation to FEP, generative model, sys1,2 etc.}{49}{section*.27}\protected@file@percent }
\pgfsyspdfmark {pgfid25}{19562754}{17216020}
\citation{eliasmith2013build}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}\leavevmode {\color  {orange}concepts}}{50}{subsection.1.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}\leavevmode {\color  {orange}How do concepts form}}{50}{subsection.1.7.3}\protected@file@percent }
\citation{blouw2016concepts}
\citation{blouw2016concepts}
\citation{Gaerdenfors}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces (a) A sensorimotor input, here a table, is compressed sequentially into a Semantic Pointer. (b) A Semantic Pointer is decompressed and returns a representation of a table. Due to the compression process the decompression results in noise. The figure is taken from Blouw et al. \cite  {blouw2016concepts}.}}{51}{figure.1.1}\protected@file@percent }
\newlabel{fig:sp}{{1.1}{51}{(a) A sensorimotor input, here a table, is compressed sequentially into a Semantic Pointer. (b) A Semantic Pointer is decompressed and returns a representation of a table. Due to the compression process the decompression results in noise. The figure is taken from Blouw et al. \cite {blouw2016concepts}}{figure.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}\leavevmode {\color  {green}Semantic Pointer Architecture}}{51}{subsection.1.7.4}\protected@file@percent }
\newlabel{subsec:gaerdenfors}{{7.5}{51}{\green {Concept space}}{subsection.1.7.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}\leavevmode {\color  {green}Concept space} }{51}{subsection.1.7.5}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{OrangeRed}{}{OrangeRed!25}{\leavevmode {\color  {OrangeRed!25}o}}\ Properties of concepts, introducing the idea of concepetual spaces and a geometry of concept space (latent space)}{51}{section*.28}\protected@file@percent }
\pgfsyspdfmark {pgfid26}{19562754}{16467553}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{Salmon}{}{Salmon!25}{\leavevmode {\color  {Salmon!25}o}}\ Gardenfords book (2004)}{52}{section*.29}\protected@file@percent }
\pgfsyspdfmark {pgfid27}{19562754}{43417216}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{Plum}{}{Plum!25}{\leavevmode {\color  {Plum!25}o}}\ isn't that already inherent since ANNs are doing linear algebra? I think the ANNs are capable of finding symmetrical relations but it could be a more explicit inductive bias/ heuristic? like we see that LLMs find some relations (man : king :: woman : queen), but it could be used explicitly for the construction of concepts. Also think about relational }{52}{section*.30}\protected@file@percent }
\pgfsyspdfmark {pgfid28}{19562754}{12233003}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6}\leavevmode {\color  {orange}Hemispheric Lateralisation}}{53}{subsection.1.7.6}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{OliveGreen}{}{OliveGreen!25}{\leavevmode {\color  {OliveGreen!25}o}}\ argument for hemispheric lateralization}{53}{section*.31}\protected@file@percent }
\pgfsyspdfmark {pgfid29}{19562754}{42411422}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{Plum}{}{Plum!25}{\leavevmode {\color  {Plum!25}o}}\ think of two types of intelligences (crystal vs fluid ?), also exploration exploitation}{54}{section*.32}\protected@file@percent }
\pgfsyspdfmark {pgfid30}{19562754}{47349376}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{Plum}{}{Plum!25}{\leavevmode {\color  {Plum!25}o}}\ We can also include barbara oakley on types of focus, deep and direct, vs broad}{54}{section*.33}\protected@file@percent }
\pgfsyspdfmark {pgfid31}{19562754}{46180651}
\citation{ciaunica_nested_2023}
\citation{vernon_embodied_2015}
\citation{Levin_2023}
\citation{ciaunica_nested_2023}
\citation{vernon_embodied_2015}
\citation{Levin_2022}
\citation{levin_computational_2019}
\@writefile{toc}{\contentsline {section}{\numberline {8}\leavevmode {\color  {green}Cognition, Nested Multi-scale Hierarchies, and Self-Organisation}}{55}{section.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}\leavevmode {\color  {green}Who am I?}}{55}{section.1.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}\leavevmode {\color  {green}The Genesis of Cognition}}{55}{subsection.1.9.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{Salmon}{}{Salmon!25}{\leavevmode {\color  {Salmon!25}o}}\ source}{55}{section*.34}\protected@file@percent }
\pgfsyspdfmark {pgfid32}{19562754}{24589734}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{Plum}{}{Plum!25}{\leavevmode {\color  {Plum!25}o}}\ is the homunculus is basically an advanced version of this?}{55}{section*.35}\protected@file@percent }
\pgfsyspdfmark {pgfid33}{19562754}{15615854}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{Salmon}{}{Salmon!25}{\leavevmode {\color  {Salmon!25}o}}\ source}{55}{section*.36}\protected@file@percent }
\pgfsyspdfmark {pgfid34}{19562754}{6618307}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{Plum}{}{Plum!25}{\leavevmode {\color  {Plum!25}o}}\ not only in structure but in representation. i.e. can we show that the imagination, the conceptual world has the same structure as the actual hardware? is the software built by the same principle as the hardware? is it growing simultaneosly? is there an isomorphism?}{56}{section*.37}\protected@file@percent }
\pgfsyspdfmark {pgfid35}{19562754}{46566585}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{Salmon}{}{Salmon!25}{\leavevmode {\color  {Salmon!25}o}}\ Serge paper on embodiment, sensorimotor information}{56}{section*.38}\protected@file@percent }
\pgfsyspdfmark {pgfid36}{19562754}{38425558}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{Salmon}{}{Salmon!25}{\leavevmode {\color  {Salmon!25}o}}\ source}{56}{section*.39}\protected@file@percent }
\pgfsyspdfmark {pgfid37}{19562754}{27461931}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{Plum}{}{Plum!25}{\leavevmode {\color  {Plum!25}o}}\  This may be a primitive precursor to symbolic thought. Perhaps even to visualization and imagination. Perhaps moving from bioelectrical pattern representation of the brain, which is in a sense the first counterfactual, this may be the first primitive version of symbolic? representation, and allude to the brain being a machine to store more complex patterns. }{56}{section*.40}\protected@file@percent }
\pgfsyspdfmark {pgfid38}{19562754}{10132211}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ Show the work of Lenia, how they do it, and what they have achieved. Also, the Gecko thingy from Distill.pub}{56}{section*.41}\protected@file@percent }
\pgfsyspdfmark {pgfid39}{19562754}{7033815}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}\leavevmode {\color  {green}Computational boundary of the self}}{57}{subsection.1.9.2}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{Plum}{}{Plum!25}{\leavevmode {\color  {Plum!25}o}}\ introduce cognitive light cone and include stuff from computational boundary of the self}{57}{section*.42}\protected@file@percent }
\pgfsyspdfmark {pgfid40}{14521514}{45970845}
\pgfsyspdfmark {pgfid43}{36136525}{45983133}
\pgfsyspdfmark {pgfid44}{37987917}{45759219}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.1}\leavevmode {\color  {green}Body Patterning and Cognition: A Common Origin}}{57}{subsubsection.1.9.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.2}\leavevmode {\color  {green}Multicellularity vs. Cancer: The Shifting Boundary of the Self}}{57}{subsubsection.1.9.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.3}\leavevmode {\color  {green}Defining Individuation From a Cognitive Perspective}}{57}{subsubsection.1.9.2.3}\protected@file@percent }
\citation{vernon_embodied_2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}\leavevmode {\color  {orange}Embodied cognition and circular causality: on the role of constitutive autonomy in the reciprocal coupling of perception and action}}{59}{subsection.1.9.3}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{cyan}{}{cyan!25}{\leavevmode {\color  {cyan!25}o}}\ I would argue that the autonomy always depends on the levels above and below, in the hierarchy. i.e., we are part of a society, but we are also constituted of and encapsulated by simpler elements. Therefore we share the goals of those levels. Being part of an environment imposes an inductive bias.}{59}{section*.43}\protected@file@percent }
\pgfsyspdfmark {pgfid45}{19562754}{29597772}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{OliveGreen}{}{OliveGreen!25}{\leavevmode {\color  {OliveGreen!25}o}}\ relate (or reference) this to maxwells explanation of active inference.}{59}{section*.44}\protected@file@percent }
\pgfsyspdfmark {pgfid46}{19562754}{21975572}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{OliveGreen}{}{OliveGreen!25}{\leavevmode {\color  {OliveGreen!25}o}}\ this is again FEP, homeostasis, allostasis}{59}{section*.45}\protected@file@percent }
\pgfsyspdfmark {pgfid47}{19562754}{12815096}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{OliveGreen}{}{OliveGreen!25}{\leavevmode {\color  {OliveGreen!25}o}}\ relate this to piccininis distinctions of emergence. Also to michael levins observer dependent cognition (sth like that?) where function emerges by viewing the system in different ways.}{60}{section*.46}\protected@file@percent }
\pgfsyspdfmark {pgfid48}{19562754}{20239318}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{OliveGreen}{}{OliveGreen!25}{\leavevmode {\color  {OliveGreen!25}o}}\ we are not only reactive}{60}{section*.47}\protected@file@percent }
\pgfsyspdfmark {pgfid49}{19562754}{15520727}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{OliveGreen}{}{OliveGreen!25}{\leavevmode {\color  {OliveGreen!25}o}}\ link to counterfactuals}{60}{section*.48}\protected@file@percent }
\pgfsyspdfmark {pgfid50}{19562754}{13341656}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{yellow}{\leavevmode {\color  {yellow}o}}\ link to hemispheres. apprehension vs ?}{60}{section*.49}\protected@file@percent }
\pgfsyspdfmark {pgfid51}{19562754}{10306976}
\@writefile{toc}{\contentsline {section}{\numberline {10}\leavevmode {\color  {orange}What is a Holarchy?}}{61}{section.1.10}\protected@file@percent }
\citation{friston_world_2021}
\citation{Ramstead_Kirchhoff_Friston_2020}
\citation{caucheteux_evidence_2023}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}\leavevmode {\color  {orange}Active Inference}}{62}{subsection.1.10.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{cyan}{}{cyan!25}{\leavevmode {\color  {cyan!25}o}}\ From Maxwell Ramstead Tutorial on active inference}{62}{section*.50}\protected@file@percent }
\pgfsyspdfmark {pgfid52}{19562754}{21792353}
\citation{Park_Friston_2013}
\citation{friston_world_2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}\leavevmode {\color  {orange}Self-organization and predictive processing}}{64}{subsection.1.10.2}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{OliveGreen}{}{OliveGreen!25}{\leavevmode {\color  {OliveGreen!25}o}}\ LLMs also create a generative model, but lack the causal structure.}{64}{section*.51}\protected@file@percent }
\pgfsyspdfmark {pgfid53}{19562754}{16554287}
\@writefile{toc}{\contentsline {section}{\numberline {11}\leavevmode {\color  {red}Implications/ Consequences of the theory}}{65}{section.1.11}\protected@file@percent }
\citation{causal_representation_learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1}\leavevmode {\color  {red}review of human capabilities and comparing PPL vs LLMs}}{66}{subsection.1.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {11.1.1}\leavevmode {\color  {red}World Model}}{66}{subsubsection.1.11.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {11.1.2}\leavevmode {\color  {red}Bayesian Model}}{66}{subsubsection.1.11.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {11.1.3}\leavevmode {\color  {red}Compositionality}}{66}{subsubsection.1.11.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {11.1.4}\leavevmode {\color  {orange}Causality}}{66}{subsubsection.1.11.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {11.1.5}\leavevmode {\color  {red}Correlation Does Not Imply Causation}}{66}{subsubsection.1.11.1.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces title}}{67}{table.1.1}\protected@file@percent }
\newlabel{}{{1.1}{67}{title}{table.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {11.1.6}\leavevmode {\color  {red}Abduction}}{67}{subsubsection.1.11.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {11.1.7}\leavevmode {\color  {red}System 1 \& 2}}{67}{subsubsection.1.11.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {11.1.8}\leavevmode {\color  {red}Concepts}}{67}{subsubsection.1.11.1.8}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{cyan}{}{cyan!25}{\leavevmode {\color  {cyan!25}o}}\ from JB: LLMs learn how to complete sequences, they do statistics over patterns}{67}{section*.52}\protected@file@percent }
\pgfsyspdfmark {pgfid54}{19562754}{36967935}
\@writefile{toc}{\contentsline {chapter}{Glossary}{68}{section*.53}\protected@file@percent }
\bibstyle{unsrt}
\bibdata{../auxiliary/ref.bib}
\bibcite{dehaene_symbols_2022}{1}
\bibcite{ellis_dreamcoder_2021}{2}
\bibcite{blouw2016concepts}{3}
\bibcite{Ullman_Spelke_Battaglia_Tenenbaum_2017}{4}
\bibcite{Lake_Ullman_Tenenbaum_Gershman_2017}{5}
\bibcite{rule_child_2020}{6}
\bibcite{friston_free-energy_2010}{7}
\bibcite{friston_world_2021}{8}
\bibcite{Pearl_2018}{9}
\bibcite{burks1946peirce}{10}
\bibcite{kwisthout2013most}{11}
\bibcite{Ramstead_Kirchhoff_Friston_2020}{12}
\bibcite{Kahneman11}{13}
\bibcite{ball2013surfaces}{14}
\bibcite{wolfram2023chatgpt}{15}
\bibcite{Vaswani_Shazeer_Parmar_Uszkoreit_Jones_Gomez_Kaiser_Polosukhin_2017}{16}
\bibcite{lake_building_2016}{17}
\bibcite{garcez_neurosymbolic_2020}{18}
\bibcite{hinton1995wake}{19}
\bibcite{Ellis_Wong_Nye_Sable-Meyer_Cary_Morales_Hewitt_Solar-Lezama_Tenenbaum}{20}
\bibcite{fijalkow_scaling_2021}{21}
\bibcite{bengio_flow_2021}{22}
\bibcite{bengio2023gflownet}{23}
\bibcite{malkin_trajectory_2022}{24}
\bibcite{hu_gflownet-em_2023}{25}
\bibcite{kim_compound_2019}{26}
\bibcite{ullman_theory_2012}{27}
\bibcite{gulwani_program_2017}{28}
\bibcite{sep-leibniz-logic-influence}{29}
\bibcite{sep-language-thought}{30}
\bibcite{sep-goedel-incompleteness}{31}
\bibcite{JCopeland2004-JCOTET}{32}
\bibcite{chomsky1959certain}{33}
\bibcite{al_roumi_mental_2021}{34}
\bibcite{garcez2020neurosymbolic}{35}
\bibcite{Blank_2023}{36}
\bibcite{piantadosi2021computational}{37}
\bibcite{piantasodi2022meaning}{38}
\bibcite{do2021neural}{39}
\bibcite{santoro2021symbolic}{40}
\bibcite{hofstadter_gdel_1979}{41}
\bibcite{blokpoel2018deep}{42}
\bibcite{fodor1983modularity}{43}
\bibcite{lewis2018memory}{44}
\bibcite{gentner1983structure}{45}
\bibcite{haselager1997}{46}
\bibcite{palmer1978fundamental}{47}
\bibcite{zeithamova_brain_2019}{48}
\bibcite{eliasmith2013build}{49}
\bibcite{Gaerdenfors}{50}
\bibcite{ciaunica_nested_2023}{51}
\bibcite{vernon_embodied_2015}{52}
\bibcite{Levin_2023}{53}
\bibcite{Levin_2022}{54}
\bibcite{levin_computational_2019}{55}
\bibcite{caucheteux_evidence_2023}{56}
\bibcite{Park_Friston_2013}{57}
\bibcite{causal_representation_learning}{58}
\@writefile{toc}{\contentsline {section}{\numberline {1}Domain Specific Language (DSL)}{73}{section.Alph0.1}\protected@file@percent }
\newlabel{app:dsl}{{1}{73}{Domain Specific Language (DSL)}{section.Alph0.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Semantics}{73}{subsection.Alph0.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Primitive Types}{74}{subsection.Alph0.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Experiment Hyperparameters}{75}{section.Alph0.2}\protected@file@percent }
\newlabel{app:hyperparams}{{2}{75}{Experiment Hyperparameters}{section.Alph0.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Hyperparameters}}{75}{table.Alph0.2}\protected@file@percent }
\newlabel{tab:hyperparams}{{2}{75}{Hyperparameters}{table.Alph0.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Model Parameters}{76}{section.Alph0.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Model Parameters}}{76}{table.Alph0.3}\protected@file@percent }
\newlabel{table:params}{{3}{76}{Model Parameters}{table.Alph0.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Formal Grammars}{77}{section.Alph0.4}\protected@file@percent }
\newlabel{app:cfg}{{4}{77}{Formal Grammars}{section.Alph0.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Levenshtein Distance}{78}{section.Alph0.5}\protected@file@percent }
\newlabel{app:levenshtein}{{5}{78}{Levenshtein Distance}{section.Alph0.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Tasks}{78}{section.Alph0.6}\protected@file@percent }
